{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2618c9e-76ac-4213-9658-d857655307ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/energygpt/lagllama/lag-llama\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd lag-llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d2196c3-1c51-45e9-b18e-29151abaa1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3820527/2271831421.py:9: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from itertools import islice\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import torch\n",
    "from gluonts.evaluation import make_evaluation_predictions, Evaluator\n",
    "from gluonts.dataset.repository.datasets import get_dataset\n",
    "\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "import pandas as pd\n",
    "\n",
    "from lag_llama.gluon.estimator import LagLlamaEstimator\n",
    "\n",
    "import warnings  \n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "torch.set_warn_always(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "870e8c65-4beb-4e89-95ec-b52fc3b2f725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lag_llama_predictions(dataset, prediction_length, device, context_length=32, use_rope_scaling=True, num_samples=100):\n",
    "    ckpt = torch.load(\"./checkpoints/lag-llama.ckpt\", map_location=device) # Uses GPU since in this Colab we use a GPU.\n",
    "    estimator_args = ckpt[\"hyper_parameters\"][\"model_kwargs\"]\n",
    "\n",
    "    rope_scaling_arguments = {\n",
    "        \"type\": \"linear\",\n",
    "        \"factor\": max(1.0, (context_length + prediction_length) / estimator_args[\"context_length\"]),\n",
    "    }\n",
    "\n",
    "    estimator = LagLlamaEstimator(\n",
    "        ckpt_path=\"./checkpoints/lag-llama.ckpt\",\n",
    "        prediction_length=prediction_length,\n",
    "        context_length=context_length, # Lag-Llama was trained with a context length of 32, but can work with any context length\n",
    "\n",
    "        # estimator args\n",
    "        input_size=estimator_args[\"input_size\"],\n",
    "        n_layer=estimator_args[\"n_layer\"],\n",
    "        n_embd_per_head=estimator_args[\"n_embd_per_head\"],\n",
    "        n_head=estimator_args[\"n_head\"],\n",
    "        scaling=estimator_args[\"scaling\"],\n",
    "        time_feat=estimator_args[\"time_feat\"],\n",
    "        rope_scaling=rope_scaling_arguments if use_rope_scaling else None,\n",
    "\n",
    "        batch_size=32,\n",
    "        num_parallel_samples=100,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    lightning_module = estimator.create_lightning_module()\n",
    "    transformation = estimator.create_transformation()\n",
    "    predictor = estimator.create_predictor(transformation, lightning_module)\n",
    "\n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset=dataset,\n",
    "        predictor=predictor,\n",
    "        num_samples=num_samples\n",
    "    )\n",
    "    forecasts = list(forecast_it)\n",
    "    tss = list(ts_it)\n",
    "\n",
    "    return forecasts, tss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c52f3138-873b-4022-98e2-0d4853d3a657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pipelining\n",
    "def get_batched_data_fn(sub_df,\n",
    "    batch_size: int = 128, \n",
    "    context_len: int = 168, \n",
    "    horizon_len: int = 24):\n",
    "    \n",
    "    examples = defaultdict(list)\n",
    "    num_examples = 0\n",
    "    for start in range(0, len(sub_df) - (context_len + horizon_len), horizon_len):\n",
    "      num_examples += 1\n",
    "      examples[\"inputs\"].append(sub_df[\"y\"][start:(context_end := start + context_len)].tolist())\n",
    "      examples[\"outputs\"].append(sub_df[\"y\"][context_end:(context_end + horizon_len)].tolist())\n",
    "      examples['inputs_ts'].append(sub_df.index[start:(context_end := start + context_len)])\n",
    "      examples[\"outputs_ts\"].append(sub_df.index[context_end:(context_end + horizon_len)])\n",
    "\n",
    "    return examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74c09e34-d200-4f40-bcea-c780ae3246c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_building(df):\n",
    "\n",
    "    # Set numerical columns as float32\n",
    "    for col in df.columns:\n",
    "        # Check if column is not of string type\n",
    "        if df[col].dtype != 'object' and pd.api.types.is_string_dtype(df[col]) == False:\n",
    "            df[col] = df[col].astype('float32')\n",
    "    \n",
    "    # Create the Pandas\n",
    "    dataset = PandasDataset.from_long_dataframe(df, target=\"target\", item_id=\"item_id\")\n",
    "\n",
    "    \n",
    "    backtest_dataset = dataset\n",
    "    prediction_length = 24  # Define your prediction length. We use 24 here since the data is of hourly frequency\n",
    "    num_samples = 10 # number of samples sampled from the probability distribution for each timestep \n",
    "    device = torch.device(\"cuda:0\") # You can switch this to CPU or other GPUs if you'd like, depending on your environment    \n",
    "    \n",
    "    ckpt = torch.load(\"./checkpoints_bdg/lag-llama.ckpt\", map_location=device) # Uses GPU since in this Colab we use a GPU.\n",
    "\n",
    "    forecasts, tss = get_lag_llama_predictions(backtest_dataset, prediction_length, device, num_samples=num_samples)\n",
    "\n",
    "    evaluator = Evaluator()\n",
    "    agg_metrics, ts_metrics = evaluator(iter(tss), iter(forecasts))     \n",
    "    \n",
    "    res_all = []\n",
    "    for ts, fc in zip(tss, forecasts):\n",
    "        res = ts[ts.index.isin(fc.index)]\n",
    "        res.columns = ['y_true']\n",
    "        res.insert(1, 'y_pred', fc.median)\n",
    "        res_all.append(res)\n",
    "   \n",
    "    res_all_df = pd.concat(res_all).sort_index()\n",
    "    return res_all_df, agg_metrics, ts_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "056e1376-b908-47d6-b1f6-4ea14bd952d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_and_forecast_building(train, test):\n",
    "\n",
    "    prediction_length = 24\n",
    "    context_length = 168\n",
    "    num_samples = 20\n",
    "    device = \"cuda:0\"\n",
    "    \n",
    "    ckpt = torch.load(\"./checkpoints_bdg/lag-llama.ckpt\", map_location=device)\n",
    "    estimator_args = ckpt[\"hyper_parameters\"][\"model_kwargs\"]\n",
    "    \n",
    "    estimator = LagLlamaEstimator(\n",
    "            ckpt_path=\"./checkpoints_bdg/lag-llama.ckpt\",\n",
    "            prediction_length=prediction_length,\n",
    "            context_length=context_length,\n",
    "            nonnegative_pred_samples=True,\n",
    "            aug_prob=0,\n",
    "            lr=5e-4,\n",
    "    \n",
    "            # estimator args\n",
    "            input_size=estimator_args[\"input_size\"],\n",
    "            n_layer=estimator_args[\"n_layer\"],\n",
    "            n_embd_per_head=estimator_args[\"n_embd_per_head\"],\n",
    "            n_head=estimator_args[\"n_head\"],\n",
    "            time_feat=estimator_args[\"time_feat\"],\n",
    "    \n",
    "            batch_size=64,\n",
    "            num_parallel_samples=num_samples,\n",
    "            trainer_kwargs = {\"max_epochs\": 50,}, # <- lightning trainer arguments. For modification refer Lag-llama github repo\n",
    "        )    \n",
    "    \n",
    "    # Create the Pandas\n",
    "    dataset_train = PandasDataset.from_long_dataframe(train, target=\"target\", item_id=\"item_id\")    \n",
    "    predictor = estimator.train(dataset_train, cache_data=True, shuffle_buffer_length=1000)    \n",
    "  \n",
    "\n",
    "    # Create the Pandas\n",
    "    dataset_test = PandasDataset.from_long_dataframe(test, target=\"target\", item_id=\"item_id\")    \n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "            dataset=dataset_test,\n",
    "            predictor=predictor,\n",
    "            num_samples=num_samples\n",
    "        )\n",
    "\n",
    "\n",
    "    forecasts = list(forecast_it)\n",
    "    tss = list(ts_it)\n",
    "\n",
    "    evaluator = Evaluator()\n",
    "    agg_metrics, ts_metrics = evaluator(iter(tss), iter(forecasts))     \n",
    "    \n",
    "    res_all = []\n",
    "    for ts, fc in zip(tss, forecasts):\n",
    "        res = ts[ts.index.isin(fc.index)]\n",
    "        res.columns = ['y_true']\n",
    "        res.insert(1, 'y_pred', fc.median)\n",
    "        res_all.append(res)\n",
    "     \n",
    "    res_all_df = pd.concat(res_all).sort_index()\n",
    "    return res_all_df, agg_metrics, ts_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc042f12-7fcb-4d91-bf53-b6fb9b7afd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_building(df): \n",
    "    building_name = df.columns[0]\n",
    "    df.columns = ['y']\n",
    "    input_data = get_batched_data_fn(df, batch_size=500)\n",
    "    \n",
    "    windows_all = []\n",
    "    counter = 1\n",
    "    for inputs_ts, inputs, outputs_ts, outputs in zip(input_data['inputs_ts'], \n",
    "                                                      input_data['inputs'], \n",
    "                                                      input_data['outputs_ts'], \n",
    "                                                      input_data['outputs']):\n",
    "        \n",
    "        input_df = pd.DataFrame({'timestamp': inputs_ts, \n",
    "                                 'target': inputs})\n",
    "        \n",
    "        output_df = pd.DataFrame({'timestamp': outputs_ts, \n",
    "                                 'target': outputs})\n",
    "        combined = pd.concat([input_df, output_df], axis=0)\n",
    "        combined['item_id'] = str(building_name) + '_' + str(counter)\n",
    "        combined['item_id_no'] = counter\n",
    "        counter += 1\n",
    "        windows_all.append(combined)\n",
    "        \n",
    "    windows_all_df = pd.concat(windows_all)\n",
    "    windows_all_df.timestamp = pd.to_datetime(windows_all_df.timestamp)\n",
    "    windows_all_df.set_index('timestamp', inplace=True)\n",
    "\n",
    "    df = windows_all_df\n",
    "    # Set numerical columns as float32\n",
    "    for col in df.columns:\n",
    "        # Check if column is not of string type\n",
    "        if df[col].dtype != 'object' and pd.api.types.is_string_dtype(df[col]) == False:\n",
    "            df[col] = df[col].astype('float32')\n",
    "\n",
    "    th = df.item_id_no.max()/2\n",
    "    train = df[df.item_id_no <= th]\n",
    "    test  = df[df.item_id_no > th]    \n",
    "    print(datetime.now(), '#items', df.item_id_no.max(), 'split', th)\n",
    " \n",
    "    \n",
    "    test_res, test_agg_metrics, test_ts_metrics = forecast_building(test)\n",
    "    ft_res, ft_agg_metrics, ft_ts_metrics = fine_tune_and_forecast_building(train, test)\n",
    "    return test_res, test_agg_metrics, test_ts_metrics, ft_res, ft_agg_metrics, ft_ts_metrics\n",
    "\n",
    "\n",
    "\n",
    "def process_file(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    df = df.set_index(['timestamp'])    \n",
    "    df.index = pd.to_datetime(df.index)    \n",
    "    ix = pd.date_range(start = df.index.min(), end = df.index.max(), freq = 'H')\n",
    "    df = df.reindex(ix)\n",
    "    df = df.ffill()\n",
    "\n",
    "    if df.shape[1] < 2:\n",
    "        return None\n",
    "        \n",
    "    print(datetime.now(), df.shape, flush=True)\n",
    "\n",
    "    test_res_all = []\n",
    "    test_agg_metrics_all = []\n",
    "    test_ts_metrics_all = []\n",
    "\n",
    "    finetuned_res_all = []\n",
    "    finetuned_agg_metrics_all = []\n",
    "    finetuned_ts_metrics_all = []\n",
    "    \n",
    "    i = 0\n",
    "    for building_name in df.columns:\n",
    "        print(datetime.now(), i, '/', len(df.columns), building_name, flush=True)\n",
    "        df1 = df[[building_name]]#.head(24*200)\n",
    "\n",
    "        test_res, test_agg_metrics, test_ts_metrics, finetuned_res, finetuned_agg_metrics, finetuned_ts_metrics = process_building(df1)\n",
    "        test_res['building'] = building_name\n",
    "        test_res['filename'] = filename\n",
    "        test_res_all.append(test_res)\n",
    "        \n",
    "        test_ts_metrics.insert(0, 'building', building_name)\n",
    "        test_ts_metrics.insert(0, 'filename', filename)\n",
    "        test_ts_metrics = test_ts_metrics.sort_values(['forecast_start'])\n",
    "        test_ts_metrics_all.append(test_ts_metrics)\n",
    "        \n",
    "        test_agg_metrics_df = pd.DataFrame([test_agg_metrics])\n",
    "        test_agg_metrics_df.insert(0, 'building', building_name)\n",
    "        test_agg_metrics_df.insert(0, 'filename', filename)\n",
    "        test_agg_metrics_all.append(test_agg_metrics_df)\n",
    "\n",
    "        finetuned_res['building'] = building_name\n",
    "        finetuned_res['filename'] = filename\n",
    "        finetuned_res_all.append(finetuned_res)\n",
    "        \n",
    "        finetuned_ts_metrics.insert(0, 'building', building_name)\n",
    "        finetuned_ts_metrics.insert(0, 'filename', filename)\n",
    "        finetuned_ts_metrics = finetuned_ts_metrics.sort_values(['forecast_start'])\n",
    "        finetuned_ts_metrics_all.append(finetuned_ts_metrics)\n",
    "        \n",
    "        finetuned_agg_metrics_df = pd.DataFrame([finetuned_agg_metrics])\n",
    "        finetuned_agg_metrics_df.insert(0, 'building', building_name)\n",
    "        finetuned_agg_metrics_df.insert(0, 'filename', filename)\n",
    "        finetuned_agg_metrics_all.append(finetuned_agg_metrics_df)        \n",
    "\n",
    "        i += 1\n",
    "        if i % 2 == 0:\n",
    "            print(datetime.now(), 'Saving...')\n",
    "\n",
    "            test_res_all_df = pd.concat(test_res_all).round(6)\n",
    "            test_res_all_df = test_res_all_df.reset_index()\n",
    "            test_res_all_df = test_res_all_df.rename(columns={test_res_all_df.columns[0]: \"timestamp\" })\n",
    "            test_res_all_df.to_csv(f'../forecasts_finetuned/{dataset}/{os.path.basename(filename)}', index=False)            \n",
    "\n",
    "            test_ts_metrics_all_df = pd.concat(test_ts_metrics_all).round(6)\n",
    "            test_ts_metrics_all_df.to_csv(f'../results_finetuned/{dataset}/test_ts_metrics_{os.path.basename(filename)}', index=False)            \n",
    "\n",
    "            test_agg_metrics_all_df = pd.concat(test_agg_metrics_all).round(6)            \n",
    "            test_agg_metrics_all_df.to_csv(f'../results_finetuned/{dataset}/test_agg_metrics_{os.path.basename(filename)}', index=False)            \n",
    "\n",
    "            finetuned_res_all_df = pd.concat(finetuned_res_all).round(6)\n",
    "            finetuned_res_all_df = finetuned_res_all_df.reset_index()\n",
    "            finetuned_res_all_df = finetuned_res_all_df.rename(columns={finetuned_res_all_df.columns[0]: \"timestamp\" })\n",
    "            finetuned_res_all_df.to_csv(f'../forecasts_finetuned/{dataset}/{os.path.basename(filename)}', index=False)            \n",
    "\n",
    "            finetuned_ts_metrics_all_df = pd.concat(finetuned_ts_metrics_all).round(6)\n",
    "            finetuned_ts_metrics_all_df.to_csv(f'../results_finetuned/{dataset}/finetuned_ts_metrics_{os.path.basename(filename)}', index=False)            \n",
    "\n",
    "            finetuned_agg_metrics_all_df = pd.concat(finetuned_agg_metrics_all).round(6)            \n",
    "            finetuned_agg_metrics_all_df.to_csv(f'../results_finetuned/{dataset}/finetuned_agg_metrics_{os.path.basename(filename)}', index=False)            \n",
    "    \n",
    "    test_res_all_df = pd.concat(test_res_all).round(6)\n",
    "    test_res_all_df = test_res_all_df.reset_index()\n",
    "    test_res_all_df = test_res_all_df.rename(columns={test_res_all_df.columns[0]: \"timestamp\" })\n",
    "    test_res_all_df.to_csv(f'../forecasts_finetuned/{dataset}/{os.path.basename(filename)}', index=False)            \n",
    "\n",
    "    test_ts_metrics_all_df = pd.concat(test_ts_metrics_all).round(6)\n",
    "    test_ts_metrics_all_df.to_csv(f'../results_finetuned/{dataset}/test_ts_metrics_{os.path.basename(filename)}', index=False)            \n",
    "\n",
    "    test_agg_metrics_all_df = pd.concat(test_agg_metrics_all).round(6)            \n",
    "    test_agg_metrics_all_df.to_csv(f'../results_finetuned/{dataset}/test_agg_metrics_{os.path.basename(filename)}', index=False)            \n",
    "\n",
    "    finetuned_res_all_df = pd.concat(finetuned_res_all).round(6)\n",
    "    finetuned_res_all_df = finetuned_res_all_df.reset_index()\n",
    "    finetuned_res_all_df = finetuned_res_all_df.rename(columns={finetuned_res_all_df.columns[0]: \"timestamp\" })\n",
    "    finetuned_res_all_df.to_csv(f'../forecasts_finetuned/{dataset}/{os.path.basename(filename)}', index=False)            \n",
    "\n",
    "    finetuned_ts_metrics_all_df = pd.concat(finetuned_ts_metrics_all).round(6)\n",
    "    finetuned_ts_metrics_all_df.to_csv(f'../results_finetuned/{dataset}/finetuned_ts_metrics_{os.path.basename(filename)}', index=False)            \n",
    "\n",
    "    finetuned_agg_metrics_all_df = pd.concat(finetuned_agg_metrics_all).round(6)            \n",
    "    finetuned_agg_metrics_all_df.to_csv(f'../results_finetuned/{dataset}/finetuned_agg_metrics_{os.path.basename(filename)}', index=False)            \n",
    "\n",
    "    return test_res_all_df, test_ts_metrics_all_df, test_agg_metrics_all_df, finetuned_res_all_df, finetuned_ts_metrics_all_df, finetuned_agg_metrics_all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59039eff-578c-439a-b366-4d9fa89dfbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/user/BuildingsBench/BuildingsBenchData/BuildingsBench/Buildings-900K-test-csv/G51059305.csv']\n",
      "2024-08-15 11:19:22.735552 /home/user/BuildingsBench/BuildingsBenchData/BuildingsBench/Buildings-900K-test-csv/G51059305.csv\n",
      "2024-08-15 11:19:22.781498 (8760, 83)\n",
      "2024-08-15 11:19:22.781918 0 / 83 4390\n",
      "2024-08-15 11:19:22.960478 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 2269.25it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d69e3c4bd041b391cb886fa2d34fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 4.82763 (best 4.82763), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10922/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 3.87346 (best 3.87346), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10922/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 3.74765 (best 3.74765), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10922/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 3.60593 (best 3.60593), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10922/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 3.54087 (best 3.54087), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10922/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 3.44717 (best 3.44717), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10922/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 3.31279 (best 3.31279), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10922/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' was not in top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 3.14917 (best 3.14917), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10922/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 3.13100 (best 3.13100), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10922/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' was not in top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 3.07080 (best 3.07080), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10922/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 2.90979 (best 2.90979), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10922/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 2.84482 (best 2.84482), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10922/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 2.79915 (best 2.79915), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10922/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' was not in top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 2.71140 (best 2.71140), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10922/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 2.64304 (best 2.64304), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10922/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 2.59416 (best 2.59416), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10922/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 2.58024 (best 2.58024), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10922/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached 2.54142 (best 2.54142), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10922/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 2.41230 (best 2.41230), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10922/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 2.39007 (best 2.39007), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10922/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached 2.32707 (best 2.32707), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10922/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached 2.29441 (best 2.29441), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10922/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached 2.27842 (best 2.27842), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10922/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' reached 2.19734 (best 2.19734), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10922/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 2.19004 (best 2.19004), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10922/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached 2.18736 (best 2.18736), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10922/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached 2.16783 (best 2.16783), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10922/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached 2.16147 (best 2.16147), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10922/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' reached 2.09092 (best 2.09092), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10922/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached 2.05085 (best 2.05085), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10922/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached 2.02269 (best 2.02269), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10922/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached 1.98078 (best 1.98078), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10922/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached 1.93934 (best 1.93934), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10922/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached 1.92227 (best 1.92227), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10922/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 5019.02it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 11:20:51.331225 1 / 83 16464\n",
      "2024-08-15 11:20:51.498708 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 3977.54it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ba7d54147c40f897a5d94df06a5645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 1.91413 (best 1.91413), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10924/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 1.28793 (best 1.28793), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10924/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 1.11769 (best 1.11769), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10924/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 0.97641 (best 0.97641), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10924/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 0.89602 (best 0.89602), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10924/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 0.76476 (best 0.76476), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10924/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 0.70750 (best 0.70750), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10924/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 0.61333 (best 0.61333), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10924/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 0.49151 (best 0.49151), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10924/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 0.45490 (best 0.45490), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10924/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 0.36489 (best 0.36489), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10924/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 0.32496 (best 0.32496), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10924/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' was not in top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 0.21137 (best 0.21137), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10924/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 0.15045 (best 0.15045), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10924/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 0.10759 (best 0.10759), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10924/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' was not in top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached -0.02078 (best -0.02078), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10924/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached -0.12290 (best -0.12290), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10924/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached -0.12619 (best -0.12619), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10924/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached -0.20447 (best -0.20447), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10924/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached -0.29251 (best -0.29251), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10924/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached -0.34976 (best -0.34976), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10924/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached -0.39654 (best -0.39654), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10924/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached -0.41846 (best -0.41846), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10924/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached -0.48323 (best -0.48323), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10924/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached -0.48816 (best -0.48816), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10924/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached -0.57695 (best -0.57695), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10924/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached -0.58378 (best -0.58378), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10924/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached -0.61109 (best -0.61109), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10924/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' reached -0.61877 (best -0.61877), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10924/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached -0.67416 (best -0.67416), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10924/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached -0.69266 (best -0.69266), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10924/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached -0.69654 (best -0.69654), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10924/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached -0.73257 (best -0.73257), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10924/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 4696.49it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 11:22:19.782083 Saving...\n",
      "2024-08-15 11:22:19.828898 2 / 83 19360\n",
      "2024-08-15 11:22:20.023804 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 8285.75it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce2698d99cc9481098127d2ed789d99e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 2.99215 (best 2.99215), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10926/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 2.35942 (best 2.35942), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10926/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 2.22207 (best 2.22207), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10926/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 2.14049 (best 2.14049), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10926/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 2.01869 (best 2.01869), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10926/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 1.98233 (best 1.98233), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10926/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 1.95539 (best 1.95539), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10926/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 1.87535 (best 1.87535), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10926/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 1.85841 (best 1.85841), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10926/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 1.78503 (best 1.78503), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10926/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 1.77347 (best 1.77347), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10926/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' was not in top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 1.63400 (best 1.63400), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10926/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 1.57630 (best 1.57630), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10926/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' was not in top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 1.49075 (best 1.49075), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10926/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' was not in top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 1.47380 (best 1.47380), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10926/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 1.38596 (best 1.38596), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10926/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 1.38300 (best 1.38300), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10926/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 1.23851 (best 1.23851), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10926/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 1.22382 (best 1.22382), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10926/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 1.11247 (best 1.11247), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10926/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached 1.07311 (best 1.07311), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10926/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 0.98570 (best 0.98570), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10926/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached 0.97135 (best 0.97135), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10926/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached 0.90985 (best 0.90985), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10926/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached 0.87325 (best 0.87325), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10926/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached 0.71159 (best 0.71159), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10926/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached 0.70161 (best 0.70161), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10926/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached 0.65179 (best 0.65179), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10926/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached 0.61228 (best 0.61228), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10926/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached 0.59980 (best 0.59980), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10926/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached 0.53968 (best 0.53968), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10926/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached 0.48312 (best 0.48312), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10926/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 7614.56it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 11:23:47.138365 3 / 83 23149\n",
      "2024-08-15 11:23:47.307054 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 8752.39it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0770fd4f36fe4ebf9d61ec300632a5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 3.98324 (best 3.98324), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10928/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 3.39107 (best 3.39107), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10928/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 3.23291 (best 3.23291), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10928/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 3.10656 (best 3.10656), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10928/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 3.09239 (best 3.09239), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10928/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 3.01464 (best 3.01464), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10928/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 2.88451 (best 2.88451), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10928/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' was not in top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 2.78776 (best 2.78776), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10928/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 2.72381 (best 2.72381), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10928/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' was not in top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 2.70270 (best 2.70270), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10928/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 2.57995 (best 2.57995), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10928/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' was not in top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 2.56400 (best 2.56400), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10928/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' was not in top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 2.54975 (best 2.54975), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10928/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 2.44822 (best 2.44822), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10928/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 2.32512 (best 2.32512), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10928/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 2.31233 (best 2.31233), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10928/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 2.25620 (best 2.25620), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10928/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached 2.22180 (best 2.22180), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10928/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 2.16277 (best 2.16277), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10928/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 2.07113 (best 2.07113), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10928/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached 2.02863 (best 2.02863), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10928/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached 1.93521 (best 1.93521), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10928/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 1.91796 (best 1.91796), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10928/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached 1.83553 (best 1.83553), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10928/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached 1.79574 (best 1.79574), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10928/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached 1.75330 (best 1.75330), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10928/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' reached 1.71890 (best 1.71890), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10928/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' reached 1.71312 (best 1.71312), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10928/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached 1.66459 (best 1.66459), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10928/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached 1.61684 (best 1.61684), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10928/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached 1.61290 (best 1.61290), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10928/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached 1.53323 (best 1.53323), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10928/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 5071.02it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 11:25:15.768956 Saving...\n",
      "2024-08-15 11:25:15.859736 4 / 83 23184\n",
      "2024-08-15 11:25:16.027536 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 6369.56it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fe00cebd50e4354b84e2e0f1fa6bbcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 3.07459 (best 3.07459), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10930/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 2.32995 (best 2.32995), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10930/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 2.21838 (best 2.21838), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10930/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 2.13005 (best 2.13005), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10930/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 2.07478 (best 2.07478), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10930/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 2.00977 (best 2.00977), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10930/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 1.90494 (best 1.90494), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10930/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 1.84539 (best 1.84539), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10930/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 1.75861 (best 1.75861), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10930/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 1.65317 (best 1.65317), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10930/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 1.60899 (best 1.60899), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10930/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 1.52708 (best 1.52708), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10930/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 1.52093 (best 1.52093), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10930/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 1.49541 (best 1.49541), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10930/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 1.41772 (best 1.41772), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10930/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' was not in top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 1.24296 (best 1.24296), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10930/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 1.21159 (best 1.21159), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10930/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 1.14972 (best 1.14972), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10930/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 1.06378 (best 1.06378), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10930/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 0.99189 (best 0.99189), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10930/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached 0.95571 (best 0.95571), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10930/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 0.92225 (best 0.92225), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10930/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 0.83243 (best 0.83243), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10930/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 0.72385 (best 0.72385), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10930/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' reached 0.65786 (best 0.65786), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10930/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 0.65642 (best 0.65642), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10930/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached 0.59969 (best 0.59969), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10930/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached 0.57854 (best 0.57854), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10930/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached 0.50456 (best 0.50456), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10930/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 0.49442 (best 0.49442), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10930/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached 0.40314 (best 0.40314), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10930/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached 0.38094 (best 0.38094), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10930/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 8292.98it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 11:26:45.692333 5 / 83 27072\n",
      "2024-08-15 11:26:45.856216 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 4392.84it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8ecba775f84fd3a6f1f7a2ed89a53b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 2.25358 (best 2.25358), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10932/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 1.35597 (best 1.35597), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10932/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 1.21258 (best 1.21258), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10932/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 0.97199 (best 0.97199), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10932/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 0.80706 (best 0.80706), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10932/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 0.65061 (best 0.65061), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10932/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 0.57902 (best 0.57902), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10932/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 0.44045 (best 0.44045), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10932/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 0.39898 (best 0.39898), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10932/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 0.31959 (best 0.31959), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10932/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 0.22716 (best 0.22716), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10932/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 0.20425 (best 0.20425), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10932/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' was not in top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 0.11797 (best 0.11797), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10932/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 0.09198 (best 0.09198), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10932/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 0.08940 (best 0.08940), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10932/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 0.08162 (best 0.08162), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10932/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 0.03227 (best 0.03227), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10932/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached -0.05067 (best -0.05067), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10932/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached -0.09066 (best -0.09066), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10932/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached -0.09158 (best -0.09158), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10932/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached -0.17711 (best -0.17711), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10932/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached -0.19235 (best -0.19235), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10932/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached -0.21640 (best -0.21640), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10932/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached -0.27153 (best -0.27153), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10932/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached -0.28806 (best -0.28806), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10932/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached -0.31407 (best -0.31407), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10932/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached -0.32642 (best -0.32642), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10932/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached -0.35829 (best -0.35829), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10932/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached -0.45151 (best -0.45151), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10932/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached -0.51480 (best -0.51480), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10932/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached -0.51586 (best -0.51586), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10932/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached -0.59591 (best -0.59591), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10932/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 7874.44it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 11:28:16.347284 Saving...\n",
      "2024-08-15 11:28:16.475950 6 / 83 32240\n",
      "2024-08-15 11:28:16.648292 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 3905.55it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1f24263775b4db986c4193fccdb6674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 3.01395 (best 3.01395), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10934/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 1.77463 (best 1.77463), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10934/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 1.69282 (best 1.69282), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10934/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 1.51784 (best 1.51784), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10934/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 1.40679 (best 1.40679), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10934/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 1.31721 (best 1.31721), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10934/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' was not in top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 1.12090 (best 1.12090), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10934/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 1.04738 (best 1.04738), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10934/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 0.99167 (best 0.99167), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10934/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 0.90909 (best 0.90909), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10934/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 0.87887 (best 0.87887), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10934/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 0.85720 (best 0.85720), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10934/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 0.79844 (best 0.79844), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10934/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 0.79201 (best 0.79201), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10934/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 0.65472 (best 0.65472), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10934/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 0.61530 (best 0.61530), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10934/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 0.57402 (best 0.57402), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10934/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 0.56668 (best 0.56668), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10934/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 0.47211 (best 0.47211), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10934/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 0.46475 (best 0.46475), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10934/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached 0.46427 (best 0.46427), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10934/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 0.44560 (best 0.44560), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10934/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached 0.36637 (best 0.36637), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10934/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached 0.33544 (best 0.33544), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10934/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached 0.27611 (best 0.27611), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10934/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached 0.22515 (best 0.22515), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10934/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached 0.22123 (best 0.22123), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10934/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached 0.20768 (best 0.20768), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10934/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached 0.07384 (best 0.07384), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10934/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 0.02383 (best 0.02383), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10934/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached -0.05061 (best -0.05061), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10934/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' reached -0.05160 (best -0.05160), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10934/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 7693.53it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 11:29:47.811579 7 / 83 33667\n",
      "2024-08-15 11:29:47.970650 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 8742.51it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b016a6b37e054a3990f580bba7f7986a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 4.77040 (best 4.77040), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10935/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 4.28982 (best 4.28982), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10935/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 4.08749 (best 4.08749), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10935/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 3.95458 (best 3.95458), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10935/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 3.66199 (best 3.66199), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10935/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 3.60338 (best 3.60338), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10935/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 3.41816 (best 3.41816), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10935/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 3.33280 (best 3.33280), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10935/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 3.16621 (best 3.16621), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10935/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' was not in top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 3.07942 (best 3.07942), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10935/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 2.97758 (best 2.97758), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10935/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 2.92174 (best 2.92174), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10935/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' was not in top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 2.85633 (best 2.85633), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10935/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' was not in top 1\n",
      "Epoch 16, global step 850: 'train_loss' was not in top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 2.71636 (best 2.71636), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10935/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 2.67776 (best 2.67776), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10935/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 2.63391 (best 2.63391), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10935/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 2.58258 (best 2.58258), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10935/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached 2.53231 (best 2.53231), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10935/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached 2.52879 (best 2.52879), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10935/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached 2.49700 (best 2.49700), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10935/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached 2.45951 (best 2.45951), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10935/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached 2.38631 (best 2.38631), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10935/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached 2.36329 (best 2.36329), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10935/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached 2.31484 (best 2.31484), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10935/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached 2.31139 (best 2.31139), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10935/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached 2.28725 (best 2.28725), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10935/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 2.25637 (best 2.25637), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10935/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached 2.23727 (best 2.23727), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10935/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 8018.93it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 11:31:17.376727 Saving...\n",
      "2024-08-15 11:31:17.547626 8 / 83 41024\n",
      "2024-08-15 11:31:17.791285 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 8786.09it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1c4771564e445179d753ac679f09b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 2.79534 (best 2.79534), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 2.18443 (best 2.18443), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 2.05097 (best 2.05097), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 1.94568 (best 1.94568), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 1.81411 (best 1.81411), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 1.76981 (best 1.76981), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 1.63149 (best 1.63149), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 1.56916 (best 1.56916), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 1.54411 (best 1.54411), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 1.51456 (best 1.51456), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 1.39299 (best 1.39299), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 1.33784 (best 1.33784), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' was not in top 1\n",
      "Epoch 13, global step 700: 'train_loss' was not in top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 1.20882 (best 1.20882), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' was not in top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 1.12577 (best 1.12577), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 1.07695 (best 1.07695), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 1.06025 (best 1.06025), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 0.99224 (best 0.99224), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 0.95102 (best 0.95102), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 0.88045 (best 0.88045), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 0.87883 (best 0.87883), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 0.85358 (best 0.85358), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 0.84656 (best 0.84656), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached 0.71612 (best 0.71612), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 0.68772 (best 0.68772), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached 0.68058 (best 0.68058), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached 0.66506 (best 0.66506), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached 0.59169 (best 0.59169), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 0.59047 (best 0.59047), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached 0.56835 (best 0.56835), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached 0.46850 (best 0.46850), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' reached 0.45326 (best 0.45326), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' reached 0.40154 (best 0.40154), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached 0.36873 (best 0.36873), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached 0.34993 (best 0.34993), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 0.30849 (best 0.30849), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' reached 0.27998 (best 0.27998), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached 0.26072 (best 0.26072), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10937/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 4944.19it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 11:32:48.819828 9 / 83 41181\n",
      "2024-08-15 11:32:49.057153 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 8886.87it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "341ada10c1d84379a5331f13d147626d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 4.49969 (best 4.49969), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10939/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 4.05888 (best 4.05888), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10939/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 3.79662 (best 3.79662), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10939/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 3.70317 (best 3.70317), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10939/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 3.50382 (best 3.50382), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10939/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 3.46677 (best 3.46677), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10939/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 3.27133 (best 3.27133), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10939/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 3.22901 (best 3.22901), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10939/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 3.09855 (best 3.09855), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10939/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 3.01050 (best 3.01050), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10939/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 2.92111 (best 2.92111), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10939/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 2.85987 (best 2.85987), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10939/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' was not in top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 2.74704 (best 2.74704), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10939/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' was not in top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 2.71210 (best 2.71210), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10939/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 2.57663 (best 2.57663), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10939/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 2.53895 (best 2.53895), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10939/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 2.50697 (best 2.50697), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10939/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 2.46052 (best 2.46052), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10939/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 2.40562 (best 2.40562), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10939/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached 2.37417 (best 2.37417), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10939/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 2.31265 (best 2.31265), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10939/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 2.30516 (best 2.30516), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10939/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 2.17095 (best 2.17095), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10939/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached 2.09366 (best 2.09366), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10939/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' reached 2.08960 (best 2.08960), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10939/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 2.05450 (best 2.05450), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10939/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached 2.00180 (best 2.00180), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10939/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached 1.98278 (best 1.98278), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10939/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' reached 1.93328 (best 1.93328), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10939/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached 1.93143 (best 1.93143), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10939/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' reached 1.85972 (best 1.85972), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10939/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached 1.82875 (best 1.82875), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10939/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 1.79654 (best 1.79654), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10939/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached 1.73836 (best 1.73836), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10939/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 5136.84it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 11:34:19.012013 Saving...\n",
      "2024-08-15 11:34:19.320758 10 / 83 44720\n",
      "2024-08-15 11:34:19.483040 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 8552.30it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4b99f4d3f3543029b94936e44dd55fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 4.99346 (best 4.99346), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10941/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 4.31778 (best 4.31778), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10941/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 4.22726 (best 4.22726), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10941/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 4.09643 (best 4.09643), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10941/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 4.08082 (best 4.08082), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10941/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 4.05646 (best 4.05646), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10941/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 3.96144 (best 3.96144), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10941/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 3.87763 (best 3.87763), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10941/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 3.78815 (best 3.78815), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10941/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 3.68102 (best 3.68102), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10941/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' was not in top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 3.66019 (best 3.66019), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10941/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' was not in top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 3.52457 (best 3.52457), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10941/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' was not in top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 3.50913 (best 3.50913), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10941/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 3.40125 (best 3.40125), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10941/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 3.33288 (best 3.33288), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10941/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 3.28093 (best 3.28093), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10941/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached 3.18395 (best 3.18395), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10941/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 3.13377 (best 3.13377), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10941/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 3.08439 (best 3.08439), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10941/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 3.07555 (best 3.07555), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10941/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached 2.97391 (best 2.97391), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10941/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 2.96434 (best 2.96434), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10941/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached 2.83946 (best 2.83946), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10941/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached 2.81651 (best 2.81651), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10941/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached 2.77760 (best 2.77760), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10941/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached 2.65824 (best 2.65824), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10941/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 2.65361 (best 2.65361), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10941/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached 2.63263 (best 2.63263), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10941/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 3320.44it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 11:35:49.137887 11 / 83 45014\n",
      "2024-08-15 11:35:49.347056 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 8931.91it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfabed06f26a42edb9ea995ca1697c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 3.12673 (best 3.12673), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10943/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 2.46463 (best 2.46463), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10943/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 2.21234 (best 2.21234), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10943/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 2.07507 (best 2.07507), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10943/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 1.96868 (best 1.96868), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10943/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 1.83681 (best 1.83681), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10943/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 1.81121 (best 1.81121), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10943/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 1.69870 (best 1.69870), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10943/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 1.59886 (best 1.59886), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10943/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 1.50817 (best 1.50817), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10943/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 1.46708 (best 1.46708), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10943/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' was not in top 1\n",
      "Epoch 12, global step 650: 'train_loss' was not in top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 1.36019 (best 1.36019), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10943/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' was not in top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 1.29822 (best 1.29822), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10943/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 1.24342 (best 1.24342), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10943/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 1.16992 (best 1.16992), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10943/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 1.11686 (best 1.11686), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10943/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 1.08329 (best 1.08329), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10943/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 1.08124 (best 1.08124), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10943/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 1.01423 (best 1.01423), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10943/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 0.92256 (best 0.92256), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10943/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached 0.89257 (best 0.89257), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10943/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 0.85672 (best 0.85672), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10943/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached 0.77341 (best 0.77341), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10943/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 0.76207 (best 0.76207), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10943/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 0.70768 (best 0.70768), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10943/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached 0.65315 (best 0.65315), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10943/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached 0.62211 (best 0.62211), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10943/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' reached 0.55510 (best 0.55510), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10943/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' reached 0.51332 (best 0.51332), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10943/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 0.45298 (best 0.45298), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10943/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached 0.44808 (best 0.44808), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10943/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' reached 0.44140 (best 0.44140), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10943/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached 0.40577 (best 0.40577), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10943/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 4612.01it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 11:37:16.165820 Saving...\n",
      "2024-08-15 11:37:16.435806 12 / 83 46221\n",
      "2024-08-15 11:37:16.677082 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 6478.89it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a27ec9e9bef4f16bc67e2d5400789bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 4.45026 (best 4.45026), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10945/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 3.91615 (best 3.91615), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10945/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 3.68080 (best 3.68080), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10945/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 3.51940 (best 3.51940), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10945/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 3.33776 (best 3.33776), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10945/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 3.26513 (best 3.26513), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10945/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 3.09067 (best 3.09067), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10945/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 2.99358 (best 2.99358), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10945/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' was not in top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 2.85319 (best 2.85319), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10945/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 2.84519 (best 2.84519), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10945/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 2.69597 (best 2.69597), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10945/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' was not in top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 2.65680 (best 2.65680), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10945/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 2.52312 (best 2.52312), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10945/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 2.52034 (best 2.52034), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10945/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' was not in top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 2.52016 (best 2.52016), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10945/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 2.38095 (best 2.38095), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10945/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 2.30262 (best 2.30262), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10945/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 2.26315 (best 2.26315), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10945/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 2.16969 (best 2.16969), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10945/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached 2.10415 (best 2.10415), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10945/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached 2.04633 (best 2.04633), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10945/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached 2.01778 (best 2.01778), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10945/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 1.96251 (best 1.96251), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10945/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' reached 1.94309 (best 1.94309), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10945/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached 1.92734 (best 1.92734), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10945/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' reached 1.87438 (best 1.87438), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10945/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' reached 1.78235 (best 1.78235), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10945/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached 1.72628 (best 1.72628), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10945/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached 1.69116 (best 1.69116), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10945/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' reached 1.66834 (best 1.66834), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10945/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached 1.64250 (best 1.64250), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10945/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 4839.37it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 11:38:44.122463 13 / 83 60979\n",
      "2024-08-15 11:38:44.392789 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 7097.97it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c390c4084ae943fd8564bb21730ab579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 5.37347 (best 5.37347), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10947/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 4.68201 (best 4.68201), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10947/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 4.57312 (best 4.57312), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10947/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 4.44837 (best 4.44837), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10947/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 4.39403 (best 4.39403), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10947/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 4.30883 (best 4.30883), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10947/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' was not in top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 4.21583 (best 4.21583), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10947/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 4.21374 (best 4.21374), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10947/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 4.11939 (best 4.11939), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10947/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 4.04510 (best 4.04510), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10947/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 3.94709 (best 3.94709), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10947/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 3.94634 (best 3.94634), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10947/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 3.84392 (best 3.84392), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10947/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 3.82738 (best 3.82738), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10947/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 3.80250 (best 3.80250), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10947/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 3.71236 (best 3.71236), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10947/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 3.59954 (best 3.59954), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10947/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 3.53111 (best 3.53111), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10947/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 3.46799 (best 3.46799), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10947/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 3.41584 (best 3.41584), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10947/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached 3.29321 (best 3.29321), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10947/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached 3.24878 (best 3.24878), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10947/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached 3.22171 (best 3.22171), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10947/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 3.19057 (best 3.19057), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10947/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached 3.09623 (best 3.09623), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10947/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached 3.02915 (best 3.02915), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10947/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached 3.02481 (best 3.02481), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10947/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached 2.98573 (best 2.98573), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10947/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' reached 2.97193 (best 2.97193), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10947/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' reached 2.90942 (best 2.90942), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10947/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached 2.88912 (best 2.88912), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10947/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached 2.79863 (best 2.79863), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10947/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached 2.78266 (best 2.78266), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10947/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached 2.75144 (best 2.75144), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10947/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 3976.46it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 11:40:10.604349 Saving...\n",
      "2024-08-15 11:40:10.997452 14 / 83 61645\n",
      "2024-08-15 11:40:11.166453 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 7372.23it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d20502e1234fac9c2d1e087478c459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 1.86396 (best 1.86396), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10949/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 1.30427 (best 1.30427), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10949/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 1.11885 (best 1.11885), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10949/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 0.99283 (best 0.99283), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10949/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 0.80382 (best 0.80382), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10949/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 0.69309 (best 0.69309), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10949/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 0.68486 (best 0.68486), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10949/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 0.53814 (best 0.53814), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10949/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 0.45052 (best 0.45052), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10949/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 0.35899 (best 0.35899), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10949/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 0.30538 (best 0.30538), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10949/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 0.27584 (best 0.27584), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10949/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 0.23876 (best 0.23876), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10949/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 0.15199 (best 0.15199), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10949/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' was not in top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 0.07332 (best 0.07332), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10949/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 0.03390 (best 0.03390), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10949/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 0.01309 (best 0.01309), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10949/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached -0.03663 (best -0.03663), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10949/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached -0.14595 (best -0.14595), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10949/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached -0.24613 (best -0.24613), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10949/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached -0.30696 (best -0.30696), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10949/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached -0.35771 (best -0.35771), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10949/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached -0.38884 (best -0.38884), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10949/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached -0.46219 (best -0.46219), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10949/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached -0.54317 (best -0.54317), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10949/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' reached -0.59063 (best -0.59063), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10949/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached -0.63208 (best -0.63208), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10949/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' reached -0.66364 (best -0.66364), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10949/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached -0.70849 (best -0.70849), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10949/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached -0.74930 (best -0.74930), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10949/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 3999.70it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 11:41:38.068265 15 / 83 65315\n",
      "2024-08-15 11:41:38.242242 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 8444.27it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00120da41d0f4709a8f5750ad313cce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 3.81630 (best 3.81630), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10951/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 3.17379 (best 3.17379), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10951/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 3.06965 (best 3.06965), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10951/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 2.69904 (best 2.69904), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10951/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' was not in top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 2.46727 (best 2.46727), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10951/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 2.31457 (best 2.31457), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10951/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 2.13788 (best 2.13788), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10951/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 2.11020 (best 2.11020), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10951/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' was not in top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 1.98800 (best 1.98800), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10951/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' was not in top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 1.86611 (best 1.86611), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10951/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' was not in top 1\n",
      "Epoch 14, global step 750: 'train_loss' was not in top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 1.62751 (best 1.62751), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10951/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' was not in top 1\n",
      "Epoch 17, global step 900: 'train_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 1.49365 (best 1.49365), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10951/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 1.44088 (best 1.44088), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10951/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached 1.31891 (best 1.31891), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10951/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached 1.27096 (best 1.27096), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10951/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' reached 1.22289 (best 1.22289), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10951/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached 1.15341 (best 1.15341), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10951/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached 1.12675 (best 1.12675), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10951/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' reached 1.06922 (best 1.06922), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10951/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached 0.99411 (best 0.99411), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10951/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached 0.94000 (best 0.94000), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10951/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached 0.92161 (best 0.92161), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10951/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 7040.52it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 11:43:03.467546 Saving...\n",
      "2024-08-15 11:43:03.965730 16 / 83 65731\n",
      "2024-08-15 11:43:04.134566 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 4385.37it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d55b9e7f29f4b8a88b2762b9cbfafb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 3.30279 (best 3.30279), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 2.57650 (best 2.57650), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 2.44479 (best 2.44479), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 2.35800 (best 2.35800), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 2.30294 (best 2.30294), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 2.24285 (best 2.24285), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 2.13168 (best 2.13168), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 2.10417 (best 2.10417), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 2.04863 (best 2.04863), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 1.95930 (best 1.95930), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 1.94948 (best 1.94948), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' was not in top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 1.83811 (best 1.83811), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 1.79171 (best 1.79171), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 1.75735 (best 1.75735), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 1.71504 (best 1.71504), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 1.64555 (best 1.64555), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 1.56667 (best 1.56667), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 1.50248 (best 1.50248), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 1.42886 (best 1.42886), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached 1.39339 (best 1.39339), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 1.27476 (best 1.27476), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached 1.26420 (best 1.26420), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 1.17306 (best 1.17306), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached 1.09592 (best 1.09592), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached 1.09403 (best 1.09403), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 1.05728 (best 1.05728), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' reached 1.00904 (best 1.00904), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached 0.99083 (best 0.99083), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached 0.96406 (best 0.96406), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' reached 0.84425 (best 0.84425), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' reached 0.82246 (best 0.82246), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached 0.79465 (best 0.79465), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 0.75213 (best 0.75213), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached 0.69212 (best 0.69212), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' reached 0.66496 (best 0.66496), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached 0.66263 (best 0.66263), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10953/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 7228.50it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 11:44:32.464485 17 / 83 66947\n",
      "2024-08-15 11:44:32.664314 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 7751.03it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86db9a390ecf443b9f4bb789fe7b8c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 4.74000 (best 4.74000), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10955/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 4.19265 (best 4.19265), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10955/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 3.99830 (best 3.99830), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10955/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 3.67041 (best 3.67041), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10955/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 3.57044 (best 3.57044), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10955/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 3.50903 (best 3.50903), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10955/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 3.46378 (best 3.46378), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10955/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 3.32895 (best 3.32895), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10955/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 3.30452 (best 3.30452), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10955/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 3.29367 (best 3.29367), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10955/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 3.18099 (best 3.18099), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10955/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 3.16963 (best 3.16963), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10955/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 3.14366 (best 3.14366), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10955/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 3.06542 (best 3.06542), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10955/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' was not in top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 2.99251 (best 2.99251), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10955/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 2.91983 (best 2.91983), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10955/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 2.90193 (best 2.90193), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10955/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 2.79220 (best 2.79220), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10955/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached 2.72086 (best 2.72086), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10955/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 2.68991 (best 2.68991), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10955/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 2.63842 (best 2.63842), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10955/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached 2.59973 (best 2.59973), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10955/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 2.54771 (best 2.54771), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10955/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached 2.50127 (best 2.50127), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10955/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached 2.49680 (best 2.49680), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10955/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' reached 2.45763 (best 2.45763), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10955/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached 2.34942 (best 2.34942), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10955/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached 2.34252 (best 2.34252), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10955/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 2.28312 (best 2.28312), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10955/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 7580.81it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 11:45:59.798584 Saving...\n",
      "2024-08-15 11:46:00.671587 18 / 83 69584\n",
      "2024-08-15 11:46:00.992492 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 6982.19it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2eb82f0295c48efba3b92cd0d8893b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 3.52860 (best 3.52860), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10957/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 2.88753 (best 2.88753), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10957/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 2.69481 (best 2.69481), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10957/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 2.42061 (best 2.42061), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10957/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 2.32691 (best 2.32691), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10957/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 2.26103 (best 2.26103), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10957/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 2.17400 (best 2.17400), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10957/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 2.09738 (best 2.09738), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10957/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 2.09491 (best 2.09491), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10957/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 2.06597 (best 2.06597), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10957/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 2.06402 (best 2.06402), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10957/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 1.88624 (best 1.88624), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10957/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 1.87077 (best 1.87077), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10957/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' was not in top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 1.76084 (best 1.76084), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10957/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 1.75474 (best 1.75474), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10957/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 1.68814 (best 1.68814), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10957/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 1.57235 (best 1.57235), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10957/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 1.55365 (best 1.55365), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10957/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 1.50616 (best 1.50616), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10957/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 1.43067 (best 1.43067), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10957/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached 1.42366 (best 1.42366), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10957/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 1.39653 (best 1.39653), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10957/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached 1.38272 (best 1.38272), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10957/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' reached 1.32933 (best 1.32933), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10957/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached 1.26762 (best 1.26762), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10957/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached 1.24810 (best 1.24810), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10957/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached 1.22967 (best 1.22967), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10957/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached 1.13517 (best 1.13517), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10957/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached 1.11517 (best 1.11517), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10957/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached 1.07820 (best 1.07820), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10957/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' reached 1.06529 (best 1.06529), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10957/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached 0.99658 (best 0.99658), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10957/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 6535.74it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 11:47:30.559275 19 / 83 69942\n",
      "2024-08-15 11:47:30.733896 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 3661.72it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c565b070b67b4379b3fde76b07d2d4a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 6.16026 (best 6.16026), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10959/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 5.59442 (best 5.59442), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10959/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 5.40057 (best 5.40057), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10959/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 5.19798 (best 5.19798), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10959/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 5.05363 (best 5.05363), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10959/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 5.03075 (best 5.03075), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10959/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 4.88418 (best 4.88418), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10959/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 4.88033 (best 4.88033), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10959/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 4.76077 (best 4.76077), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10959/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 4.70051 (best 4.70051), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10959/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' was not in top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 4.58754 (best 4.58754), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10959/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 4.53255 (best 4.53255), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10959/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 4.50026 (best 4.50026), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10959/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 4.47337 (best 4.47337), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10959/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 4.39728 (best 4.39728), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10959/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 4.32614 (best 4.32614), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10959/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 4.24556 (best 4.24556), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10959/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 4.15890 (best 4.15890), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10959/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 4.12804 (best 4.12804), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10959/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 4.03291 (best 4.03291), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10959/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 3.98094 (best 3.98094), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10959/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 3.96213 (best 3.96213), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10959/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached 3.83628 (best 3.83628), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10959/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 3.78763 (best 3.78763), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10959/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 3.76410 (best 3.76410), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10959/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached 3.72322 (best 3.72322), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10959/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached 3.65495 (best 3.65495), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10959/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached 3.63725 (best 3.63725), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10959/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' reached 3.59321 (best 3.59321), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10959/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached 3.53056 (best 3.53056), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10959/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 3.50055 (best 3.50055), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10959/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 3713.15it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 11:48:57.272158 Saving...\n",
      "2024-08-15 11:48:57.787376 20 / 83 85712\n",
      "2024-08-15 11:48:57.953154 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 4951.30it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6f608b70f04d439a5e21b769e52096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 4.15919 (best 4.15919), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10961/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 3.33045 (best 3.33045), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10961/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 3.18949 (best 3.18949), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10961/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 3.01531 (best 3.01531), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10961/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 2.93467 (best 2.93467), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10961/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 2.71102 (best 2.71102), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10961/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' was not in top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 2.61018 (best 2.61018), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10961/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 2.43717 (best 2.43717), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10961/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' was not in top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 2.34314 (best 2.34314), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10961/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 2.25939 (best 2.25939), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10961/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 2.19711 (best 2.19711), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10961/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' was not in top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 2.18715 (best 2.18715), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10961/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' was not in top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 2.15391 (best 2.15391), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10961/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 2.01448 (best 2.01448), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10961/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 1.97583 (best 1.97583), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10961/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 1.96005 (best 1.96005), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10961/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached 1.94176 (best 1.94176), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10961/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 1.88026 (best 1.88026), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10961/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 1.86587 (best 1.86587), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10961/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 1.85393 (best 1.85393), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10961/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached 1.78024 (best 1.78024), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10961/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 1.75677 (best 1.75677), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10961/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached 1.74711 (best 1.74711), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10961/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached 1.67986 (best 1.67986), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10961/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached 1.67920 (best 1.67920), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10961/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' reached 1.60977 (best 1.60977), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10961/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' reached 1.57560 (best 1.57560), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10961/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached 1.57294 (best 1.57294), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10961/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 1.53534 (best 1.53534), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10961/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' reached 1.52829 (best 1.52829), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10961/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached 1.50357 (best 1.50357), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10961/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 6613.99it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 11:50:25.764109 21 / 83 92493\n",
      "2024-08-15 11:50:26.074587 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 3500.29it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13a821c1e0f94f2c93680ef7748d42dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 3.03404 (best 3.03404), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10963/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 2.32227 (best 2.32227), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10963/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 2.08662 (best 2.08662), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10963/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 1.89595 (best 1.89595), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10963/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 1.82828 (best 1.82828), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10963/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 1.79777 (best 1.79777), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10963/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 1.58133 (best 1.58133), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10963/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 1.51986 (best 1.51986), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10963/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 1.45211 (best 1.45211), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10963/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' was not in top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 1.37018 (best 1.37018), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10963/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 1.33096 (best 1.33096), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10963/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 1.30218 (best 1.30218), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10963/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 1.19982 (best 1.19982), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10963/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 1.11178 (best 1.11178), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10963/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 1.07694 (best 1.07694), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10963/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 1.07208 (best 1.07208), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10963/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 0.98461 (best 0.98461), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10963/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 0.94818 (best 0.94818), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10963/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 0.87441 (best 0.87441), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10963/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 0.86236 (best 0.86236), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10963/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached 0.77379 (best 0.77379), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10963/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 0.70869 (best 0.70869), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10963/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 0.69973 (best 0.69973), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10963/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached 0.66040 (best 0.66040), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10963/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached 0.56090 (best 0.56090), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10963/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 0.52714 (best 0.52714), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10963/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached 0.50748 (best 0.50748), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10963/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached 0.43523 (best 0.43523), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10963/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' reached 0.34674 (best 0.34674), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10963/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached 0.30518 (best 0.30518), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10963/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached 0.27752 (best 0.27752), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10963/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' reached 0.24311 (best 0.24311), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10963/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 7631.90it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 11:51:54.523979 Saving...\n",
      "2024-08-15 11:51:55.115584 22 / 83 93197\n",
      "2024-08-15 11:51:55.271535 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 8435.36it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0d3284415e49ca8b69b223c0e72fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 3.02475 (best 3.02475), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10965/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 2.34501 (best 2.34501), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10965/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 2.17374 (best 2.17374), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10965/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' was not in top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 1.91929 (best 1.91929), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10965/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 1.80094 (best 1.80094), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10965/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 1.68081 (best 1.68081), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10965/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 1.59943 (best 1.59943), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10965/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 1.57036 (best 1.57036), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10965/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 1.46702 (best 1.46702), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10965/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 1.45430 (best 1.45430), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10965/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 1.36710 (best 1.36710), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10965/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 1.28026 (best 1.28026), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10965/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' was not in top 1\n",
      "Epoch 14, global step 750: 'train_loss' was not in top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 1.13374 (best 1.13374), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10965/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 1.12755 (best 1.12755), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10965/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 1.05917 (best 1.05917), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10965/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached 0.91293 (best 0.91293), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10965/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 0.90327 (best 0.90327), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10965/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 0.84439 (best 0.84439), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10965/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached 0.80228 (best 0.80228), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10965/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 0.77343 (best 0.77343), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10965/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached 0.76577 (best 0.76577), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10965/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' reached 0.64677 (best 0.64677), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10965/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached 0.64025 (best 0.64025), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10965/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached 0.52360 (best 0.52360), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10965/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached 0.47964 (best 0.47964), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10965/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached 0.44927 (best 0.44927), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10965/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached 0.44475 (best 0.44475), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10965/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached 0.36577 (best 0.36577), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10965/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached 0.35898 (best 0.35898), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10965/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 5134.28it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 11:53:24.618710 23 / 83 94963\n",
      "2024-08-15 11:53:24.779917 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 7519.91it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6e160967af84eb1861c0adf47ef6a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 5.29711 (best 5.29711), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10967/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 4.50593 (best 4.50593), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10967/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 4.41993 (best 4.41993), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10967/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 4.28617 (best 4.28617), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10967/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 4.16434 (best 4.16434), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10967/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 4.07099 (best 4.07099), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10967/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 3.99327 (best 3.99327), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10967/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 3.89825 (best 3.89825), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10967/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 3.79967 (best 3.79967), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10967/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 3.73135 (best 3.73135), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10967/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 3.59868 (best 3.59868), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10967/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' was not in top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 3.42957 (best 3.42957), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10967/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 3.42366 (best 3.42366), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10967/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' was not in top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 3.39574 (best 3.39574), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10967/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 3.30110 (best 3.30110), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10967/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 3.19613 (best 3.19613), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10967/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 3.17128 (best 3.17128), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10967/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 3.04411 (best 3.04411), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10967/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 2.91608 (best 2.91608), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10967/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 2.91412 (best 2.91412), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10967/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached 2.89629 (best 2.89629), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10967/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 2.81114 (best 2.81114), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10967/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 2.65693 (best 2.65693), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10967/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached 2.61806 (best 2.61806), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10967/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached 2.58985 (best 2.58985), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10967/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' reached 2.52673 (best 2.52673), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10967/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached 2.50532 (best 2.50532), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10967/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached 2.47956 (best 2.47956), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10967/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 2.47063 (best 2.47063), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10967/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached 2.42099 (best 2.42099), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10967/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' reached 2.41082 (best 2.41082), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10967/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached 2.38961 (best 2.38961), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10967/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached 2.34462 (best 2.34462), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10967/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 8057.23it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 11:54:53.205054 Saving...\n",
      "2024-08-15 11:54:53.859570 24 / 83 95088\n",
      "2024-08-15 11:54:54.014865 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 1537.21it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0a8f42dab448d893a88d16627cc7b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 5.97063 (best 5.97063), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10969/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 5.53873 (best 5.53873), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10969/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 5.28183 (best 5.28183), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10969/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 5.08676 (best 5.08676), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10969/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 4.94548 (best 4.94548), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10969/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 4.79857 (best 4.79857), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10969/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 4.75573 (best 4.75573), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10969/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 4.61012 (best 4.61012), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10969/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 4.52892 (best 4.52892), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10969/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 4.47576 (best 4.47576), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10969/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' was not in top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 4.32820 (best 4.32820), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10969/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 4.19936 (best 4.19936), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10969/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 4.12742 (best 4.12742), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10969/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' was not in top 1\n",
      "Epoch 15, global step 800: 'train_loss' was not in top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 4.03316 (best 4.03316), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10969/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 3.90705 (best 3.90705), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10969/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 3.77008 (best 3.77008), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10969/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached 3.67128 (best 3.67128), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10969/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 3.58399 (best 3.58399), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10969/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 3.52493 (best 3.52493), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10969/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached 3.48859 (best 3.48859), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10969/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached 3.38431 (best 3.38431), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10969/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached 3.28918 (best 3.28918), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10969/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached 3.28492 (best 3.28492), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10969/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached 3.23892 (best 3.23892), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10969/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached 3.20225 (best 3.20225), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10969/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached 3.17203 (best 3.17203), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10969/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 3.14079 (best 3.14079), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10969/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached 3.09903 (best 3.09903), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10969/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 8065.28it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 11:56:26.868183 25 / 83 99053\n",
      "2024-08-15 11:56:27.468432 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 8820.16it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef0e1a158d7f403097ec4bd056dda65a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 3.03813 (best 3.03813), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10970/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 2.44245 (best 2.44245), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10970/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 2.28898 (best 2.28898), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10970/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' was not in top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 1.95099 (best 1.95099), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10970/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 1.80768 (best 1.80768), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10970/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 1.70326 (best 1.70326), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10970/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 1.59695 (best 1.59695), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10970/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 1.54877 (best 1.54877), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10970/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 1.51151 (best 1.51151), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10970/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' was not in top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 1.36946 (best 1.36946), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10970/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 1.36173 (best 1.36173), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10970/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 1.31275 (best 1.31275), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10970/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 1.25757 (best 1.25757), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10970/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' was not in top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 1.25514 (best 1.25514), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10970/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 1.16559 (best 1.16559), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10970/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 1.12791 (best 1.12791), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10970/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 1.07280 (best 1.07280), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10970/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 1.00325 (best 1.00325), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10970/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 0.97192 (best 0.97192), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10970/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 0.93236 (best 0.93236), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10970/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 0.90430 (best 0.90430), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10970/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 0.89596 (best 0.89596), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10970/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached 0.80571 (best 0.80571), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10970/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached 0.75838 (best 0.75838), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10970/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 0.73356 (best 0.73356), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10970/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached 0.67807 (best 0.67807), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10970/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' reached 0.67295 (best 0.67295), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10970/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' reached 0.60480 (best 0.60480), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10970/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached 0.58528 (best 0.58528), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10970/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached 0.53822 (best 0.53822), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10970/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached 0.51051 (best 0.51051), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10970/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached 0.48301 (best 0.48301), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10970/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' reached 0.45382 (best 0.45382), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10970/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 6277.53it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 11:57:57.526134 Saving...\n",
      "2024-08-15 11:57:58.123974 26 / 83 100419\n",
      "2024-08-15 11:57:58.285162 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 8824.72it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d6128bdcc204d2f970ee0f063ae6db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 5.09082 (best 5.09082), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10972/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 4.45049 (best 4.45049), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10972/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 4.24156 (best 4.24156), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10972/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' was not in top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 3.99420 (best 3.99420), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10972/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 3.85520 (best 3.85520), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10972/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 3.77446 (best 3.77446), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10972/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 3.61552 (best 3.61552), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10972/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 3.53516 (best 3.53516), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10972/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' was not in top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 3.48467 (best 3.48467), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10972/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 3.46056 (best 3.46056), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10972/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 3.28800 (best 3.28800), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10972/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' was not in top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 3.22033 (best 3.22033), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10972/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 3.19201 (best 3.19201), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10972/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 3.14720 (best 3.14720), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10972/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 3.13848 (best 3.13848), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10972/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 3.05288 (best 3.05288), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10972/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 3.04003 (best 3.04003), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10972/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 2.97296 (best 2.97296), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10972/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 2.90685 (best 2.90685), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10972/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 2.88725 (best 2.88725), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10972/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 2.77696 (best 2.77696), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10972/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 2.76532 (best 2.76532), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10972/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached 2.69988 (best 2.69988), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10972/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 2.62016 (best 2.62016), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10972/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 2.56930 (best 2.56930), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10972/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached 2.53495 (best 2.53495), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10972/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached 2.49796 (best 2.49796), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10972/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' reached 2.49580 (best 2.49580), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10972/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached 2.39319 (best 2.39319), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10972/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached 2.39314 (best 2.39314), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10972/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached 2.36717 (best 2.36717), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10972/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 2.31565 (best 2.31565), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10972/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached 2.31502 (best 2.31502), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10972/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached 2.29615 (best 2.29615), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10972/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 7331.63it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 11:59:26.261117 27 / 83 104032\n",
      "2024-08-15 11:59:26.423294 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 8441.24it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1adf73af8dc4428b6772a4ce55ddfc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 4.58060 (best 4.58060), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 3.68727 (best 3.68727), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 3.56466 (best 3.56466), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 3.45455 (best 3.45455), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 3.31940 (best 3.31940), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 3.25298 (best 3.25298), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 3.21949 (best 3.21949), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 3.06989 (best 3.06989), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 3.05848 (best 3.05848), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 3.05091 (best 3.05091), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 2.98869 (best 2.98869), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 2.93443 (best 2.93443), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 2.87730 (best 2.87730), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' was not in top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 2.74475 (best 2.74475), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' was not in top 1\n",
      "Epoch 16, global step 850: 'train_loss' was not in top 1\n",
      "Epoch 17, global step 900: 'train_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 2.60101 (best 2.60101), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 2.59342 (best 2.59342), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached 2.47102 (best 2.47102), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 2.41500 (best 2.41500), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 2.38590 (best 2.38590), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 2.33480 (best 2.33480), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 2.32956 (best 2.32956), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached 2.31422 (best 2.31422), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached 2.28497 (best 2.28497), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 2.23842 (best 2.23842), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 2.16707 (best 2.16707), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached 2.12491 (best 2.12491), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached 2.08928 (best 2.08928), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached 2.07564 (best 2.07564), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' reached 2.03958 (best 2.03958), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached 2.03408 (best 2.03408), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached 1.98408 (best 1.98408), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 1.96804 (best 1.96804), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached 1.89779 (best 1.89779), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached 1.88061 (best 1.88061), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached 1.85290 (best 1.85290), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10974/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 5018.69it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:00:54.325845 Saving...\n",
      "2024-08-15 12:00:55.036018 28 / 83 109155\n",
      "2024-08-15 12:00:55.194945 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 8701.27it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fd3b7272b4545f987df068d68f85040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 1.82995 (best 1.82995), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10976/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 1.23785 (best 1.23785), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10976/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 1.09029 (best 1.09029), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10976/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 0.99690 (best 0.99690), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10976/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 0.88631 (best 0.88631), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10976/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 0.78258 (best 0.78258), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10976/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' was not in top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 0.61175 (best 0.61175), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10976/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 0.58908 (best 0.58908), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10976/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 0.47306 (best 0.47306), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10976/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' was not in top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 0.33860 (best 0.33860), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10976/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 0.27864 (best 0.27864), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10976/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' was not in top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 0.13873 (best 0.13873), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10976/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' was not in top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 0.09437 (best 0.09437), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10976/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 0.05142 (best 0.05142), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10976/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached -0.08928 (best -0.08928), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10976/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached -0.10554 (best -0.10554), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10976/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached -0.21312 (best -0.21312), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10976/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached -0.25611 (best -0.25611), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10976/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached -0.28559 (best -0.28559), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10976/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached -0.38244 (best -0.38244), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10976/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached -0.38284 (best -0.38284), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10976/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' reached -0.42416 (best -0.42416), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10976/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached -0.48806 (best -0.48806), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10976/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached -0.49333 (best -0.49333), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10976/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached -0.55648 (best -0.55648), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10976/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' reached -0.56644 (best -0.56644), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10976/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached -0.58767 (best -0.58767), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10976/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached -0.59448 (best -0.59448), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10976/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached -0.68664 (best -0.68664), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10976/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached -0.70528 (best -0.70528), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10976/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached -0.74275 (best -0.74275), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10976/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached -0.75576 (best -0.75576), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10976/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 3597.22it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:02:22.460554 29 / 83 116304\n",
      "2024-08-15 12:02:23.037866 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 8636.71it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e167f851703a4178855b94c1f088ddd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 2.23773 (best 2.23773), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10978/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 1.67219 (best 1.67219), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10978/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 1.50521 (best 1.50521), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10978/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 1.35871 (best 1.35871), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10978/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 1.18844 (best 1.18844), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10978/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 1.00667 (best 1.00667), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10978/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 0.93563 (best 0.93563), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10978/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 0.84874 (best 0.84874), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10978/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 0.81736 (best 0.81736), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10978/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 0.57826 (best 0.57826), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10978/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' was not in top 1\n",
      "Epoch 11, global step 600: 'train_loss' was not in top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 0.49955 (best 0.49955), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10978/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' was not in top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 0.32074 (best 0.32074), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10978/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 0.25222 (best 0.25222), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10978/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' was not in top 1\n",
      "Epoch 17, global step 900: 'train_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 0.17608 (best 0.17608), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10978/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 0.12339 (best 0.12339), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10978/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 0.05727 (best 0.05727), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10978/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 0.05713 (best 0.05713), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10978/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached -0.01765 (best -0.01765), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10978/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached -0.04514 (best -0.04514), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10978/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached -0.12654 (best -0.12654), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10978/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached -0.15480 (best -0.15480), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10978/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached -0.24507 (best -0.24507), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10978/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' reached -0.25429 (best -0.25429), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10978/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached -0.33543 (best -0.33543), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10978/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' reached -0.39585 (best -0.39585), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10978/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached -0.42368 (best -0.42368), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10978/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached -0.42727 (best -0.42727), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10978/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached -0.44099 (best -0.44099), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10978/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached -0.47696 (best -0.47696), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10978/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached -0.48636 (best -0.48636), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10978/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 6499.81it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:03:49.805775 Saving...\n",
      "2024-08-15 12:03:50.628359 30 / 83 122131\n",
      "2024-08-15 12:03:50.796846 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 8855.32it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d215be838644a2091b4326e82db49f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 3.85632 (best 3.85632), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10980/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 3.28059 (best 3.28059), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10980/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 3.14336 (best 3.14336), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10980/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 3.04893 (best 3.04893), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10980/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 2.91983 (best 2.91983), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10980/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 2.87382 (best 2.87382), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10980/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 2.74876 (best 2.74876), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10980/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 2.66479 (best 2.66479), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10980/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' was not in top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 2.52653 (best 2.52653), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10980/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 2.43947 (best 2.43947), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10980/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' was not in top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 2.29685 (best 2.29685), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10980/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 2.28517 (best 2.28517), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10980/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 2.20232 (best 2.20232), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10980/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' was not in top 1\n",
      "Epoch 16, global step 850: 'train_loss' was not in top 1\n",
      "Epoch 17, global step 900: 'train_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 2.03356 (best 2.03356), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10980/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 2.00661 (best 2.00661), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10980/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 1.91125 (best 1.91125), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10980/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached 1.86054 (best 1.86054), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10980/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 1.77836 (best 1.77836), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10980/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached 1.67994 (best 1.67994), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10980/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached 1.61224 (best 1.61224), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10980/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' reached 1.58687 (best 1.58687), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10980/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached 1.53216 (best 1.53216), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10980/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached 1.48555 (best 1.48555), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10980/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' reached 1.39130 (best 1.39130), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10980/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached 1.38059 (best 1.38059), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10980/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached 1.33008 (best 1.33008), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10980/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached 1.32776 (best 1.32776), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10980/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached 1.32730 (best 1.32730), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10980/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 4124.53it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:05:17.280972 31 / 83 124045\n",
      "2024-08-15 12:05:17.473377 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 4898.80it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06c2d44a2dfb47f186d24d3fadba62d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 5.40773 (best 5.40773), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10982/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 4.71669 (best 4.71669), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10982/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 4.58976 (best 4.58976), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10982/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 4.49501 (best 4.49501), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10982/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 4.31983 (best 4.31983), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10982/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 4.21922 (best 4.21922), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10982/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 4.11332 (best 4.11332), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10982/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 3.92890 (best 3.92890), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10982/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 3.91299 (best 3.91299), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10982/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 3.83090 (best 3.83090), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10982/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 3.73660 (best 3.73660), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10982/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' was not in top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 3.62879 (best 3.62879), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10982/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' was not in top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 3.44886 (best 3.44886), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10982/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 3.35866 (best 3.35866), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10982/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' was not in top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 3.33512 (best 3.33512), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10982/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 3.25926 (best 3.25926), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10982/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 3.22281 (best 3.22281), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10982/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 3.17347 (best 3.17347), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10982/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 3.11577 (best 3.11577), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10982/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 3.01239 (best 3.01239), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10982/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached 2.95016 (best 2.95016), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10982/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 2.91571 (best 2.91571), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10982/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached 2.84574 (best 2.84574), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10982/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached 2.79273 (best 2.79273), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10982/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached 2.73906 (best 2.73906), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10982/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached 2.71504 (best 2.71504), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10982/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached 2.67771 (best 2.67771), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10982/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached 2.59749 (best 2.59749), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10982/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' reached 2.58007 (best 2.58007), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10982/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached 2.57677 (best 2.57677), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10982/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 7513.97it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:06:44.069821 Saving...\n",
      "2024-08-15 12:06:44.931432 32 / 83 126813\n",
      "2024-08-15 12:06:45.099859 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 3719.87it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "483fe53979594d94831349b6d6baa7ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 3.28684 (best 3.28684), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10984/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 2.81902 (best 2.81902), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10984/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 2.61340 (best 2.61340), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10984/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 2.39565 (best 2.39565), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10984/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 2.24040 (best 2.24040), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10984/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 2.13874 (best 2.13874), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10984/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 1.98237 (best 1.98237), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10984/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 1.87376 (best 1.87376), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10984/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 1.69981 (best 1.69981), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10984/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' was not in top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 1.61238 (best 1.61238), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10984/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' was not in top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 1.53046 (best 1.53046), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10984/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 1.50509 (best 1.50509), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10984/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 1.32133 (best 1.32133), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10984/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' was not in top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 1.28824 (best 1.28824), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10984/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 1.24620 (best 1.24620), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10984/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 1.21015 (best 1.21015), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10984/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 1.08740 (best 1.08740), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10984/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 1.08375 (best 1.08375), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10984/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 0.98287 (best 0.98287), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10984/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 0.95016 (best 0.95016), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10984/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 0.92731 (best 0.92731), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10984/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached 0.92513 (best 0.92513), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10984/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached 0.82361 (best 0.82361), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10984/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' reached 0.81639 (best 0.81639), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10984/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 0.78139 (best 0.78139), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10984/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached 0.74381 (best 0.74381), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10984/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached 0.65992 (best 0.65992), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10984/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached 0.64805 (best 0.64805), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10984/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached 0.59926 (best 0.59926), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10984/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached 0.57836 (best 0.57836), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10984/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 0.57362 (best 0.57362), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10984/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached 0.56558 (best 0.56558), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10984/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 1254.14it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:08:12.464398 33 / 83 129651\n",
      "2024-08-15 12:08:12.629696 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 4376.53it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa07af03802640899050265fbf7ae951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 2.82681 (best 2.82681), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10986/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 2.25738 (best 2.25738), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10986/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 2.12046 (best 2.12046), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10986/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 1.86318 (best 1.86318), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10986/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 1.82758 (best 1.82758), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10986/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 1.62936 (best 1.62936), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10986/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 1.53693 (best 1.53693), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10986/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 1.37629 (best 1.37629), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10986/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 1.28303 (best 1.28303), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10986/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' was not in top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 1.14196 (best 1.14196), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10986/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 1.13641 (best 1.13641), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10986/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 0.98895 (best 0.98895), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10986/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 0.93632 (best 0.93632), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10986/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' was not in top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 0.89247 (best 0.89247), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10986/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 0.82506 (best 0.82506), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10986/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 0.82481 (best 0.82481), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10986/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 0.67691 (best 0.67691), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10986/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 0.62216 (best 0.62216), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10986/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 0.59581 (best 0.59581), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10986/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 0.51621 (best 0.51621), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10986/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 0.46017 (best 0.46017), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10986/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached 0.35955 (best 0.35955), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10986/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached 0.35185 (best 0.35185), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10986/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached 0.29857 (best 0.29857), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10986/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached 0.24490 (best 0.24490), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10986/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached 0.23239 (best 0.23239), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10986/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached 0.22259 (best 0.22259), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10986/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached 0.16721 (best 0.16721), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10986/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached 0.07988 (best 0.07988), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10986/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached 0.06608 (best 0.06608), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10986/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached 0.05157 (best 0.05157), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10986/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 6160.70it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:09:39.177281 Saving...\n",
      "2024-08-15 12:09:40.237116 34 / 83 131315\n",
      "2024-08-15 12:09:40.504321 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 7323.26it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "138898c4eac44a7eb3c2bb01ec0c7ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 2.21885 (best 2.21885), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10988/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 1.59971 (best 1.59971), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10988/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 1.44175 (best 1.44175), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10988/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 1.26582 (best 1.26582), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10988/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 1.02534 (best 1.02534), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10988/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 0.87581 (best 0.87581), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10988/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 0.73948 (best 0.73948), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10988/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 0.67275 (best 0.67275), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10988/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 0.52852 (best 0.52852), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10988/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 0.52472 (best 0.52472), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10988/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' was not in top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 0.34278 (best 0.34278), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10988/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 0.25350 (best 0.25350), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10988/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 0.20588 (best 0.20588), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10988/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 0.19845 (best 0.19845), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10988/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' was not in top 1\n",
      "Epoch 16, global step 850: 'train_loss' was not in top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 0.09639 (best 0.09639), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10988/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 0.03238 (best 0.03238), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10988/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached -0.03387 (best -0.03387), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10988/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached -0.06365 (best -0.06365), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10988/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached -0.09582 (best -0.09582), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10988/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached -0.14509 (best -0.14509), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10988/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached -0.14597 (best -0.14597), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10988/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached -0.18579 (best -0.18579), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10988/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached -0.24691 (best -0.24691), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10988/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached -0.32138 (best -0.32138), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10988/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached -0.36295 (best -0.36295), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10988/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' reached -0.38275 (best -0.38275), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10988/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached -0.44560 (best -0.44560), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10988/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached -0.47324 (best -0.47324), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10988/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached -0.48494 (best -0.48494), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10988/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached -0.52158 (best -0.52158), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10988/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached -0.56774 (best -0.56774), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10988/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached -0.58496 (best -0.58496), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10988/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' reached -0.59887 (best -0.59887), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10988/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached -0.64180 (best -0.64180), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10988/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 4091.98it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:11:06.702094 35 / 83 139830\n",
      "2024-08-15 12:11:06.949598 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 4284.05it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbfa376ae9cd4693a69eb6d0db4593ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 3.45885 (best 3.45885), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10990/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 2.80647 (best 2.80647), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10990/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 2.69211 (best 2.69211), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10990/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 2.60308 (best 2.60308), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10990/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 2.56036 (best 2.56036), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10990/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 2.40963 (best 2.40963), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10990/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' was not in top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 2.34615 (best 2.34615), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10990/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 2.28178 (best 2.28178), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10990/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 2.17382 (best 2.17382), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10990/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 2.11750 (best 2.11750), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10990/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 2.09411 (best 2.09411), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10990/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 2.07567 (best 2.07567), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10990/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 2.01482 (best 2.01482), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10990/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' was not in top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 1.85361 (best 1.85361), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10990/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 1.80556 (best 1.80556), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10990/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 1.78314 (best 1.78314), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10990/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 1.70733 (best 1.70733), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10990/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 1.66458 (best 1.66458), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10990/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 1.59374 (best 1.59374), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10990/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 1.55882 (best 1.55882), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10990/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached 1.39201 (best 1.39201), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10990/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached 1.31584 (best 1.31584), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10990/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' reached 1.23450 (best 1.23450), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10990/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached 1.14613 (best 1.14613), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10990/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached 1.05110 (best 1.05110), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10990/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached 1.04072 (best 1.04072), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10990/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached 0.96907 (best 0.96907), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10990/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' reached 0.94485 (best 0.94485), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10990/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 5035.69it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:12:32.950708 Saving...\n",
      "2024-08-15 12:12:33.964406 36 / 83 141203\n",
      "2024-08-15 12:12:34.227157 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 6241.21it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb28cd1d20b4d2b84352e89b34667d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 3.33249 (best 3.33249), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10992/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 2.63775 (best 2.63775), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10992/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 2.46913 (best 2.46913), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10992/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 2.31771 (best 2.31771), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10992/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 2.14105 (best 2.14105), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10992/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' was not in top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 1.93200 (best 1.93200), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10992/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 1.92250 (best 1.92250), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10992/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 1.71822 (best 1.71822), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10992/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 1.68356 (best 1.68356), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10992/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 1.60283 (best 1.60283), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10992/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' was not in top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 1.47177 (best 1.47177), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10992/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' was not in top 1\n",
      "Epoch 14, global step 750: 'train_loss' was not in top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 1.36472 (best 1.36472), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10992/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 1.31834 (best 1.31834), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10992/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 1.28600 (best 1.28600), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10992/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 1.22665 (best 1.22665), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10992/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 1.17688 (best 1.17688), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10992/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached 1.12666 (best 1.12666), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10992/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 1.01569 (best 1.01569), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10992/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 1.00153 (best 1.00153), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10992/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached 0.92659 (best 0.92659), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10992/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached 0.90001 (best 0.90001), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10992/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' reached 0.83670 (best 0.83670), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10992/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 0.80845 (best 0.80845), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10992/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached 0.80534 (best 0.80534), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10992/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached 0.73914 (best 0.73914), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10992/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' reached 0.67665 (best 0.67665), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10992/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached 0.66708 (best 0.66708), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10992/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' reached 0.64878 (best 0.64878), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10992/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached 0.61085 (best 0.61085), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10992/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached 0.58216 (best 0.58216), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10992/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' reached 0.57086 (best 0.57086), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10992/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached 0.50507 (best 0.50507), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10992/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 4700.54it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:14:03.412740 37 / 83 144166\n",
      "2024-08-15 12:14:03.864854 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 7005.18it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f91e6a5e4a43c19d40a50ac722d08c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 2.04724 (best 2.04724), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10994/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 1.32955 (best 1.32955), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10994/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 1.16172 (best 1.16172), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10994/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 1.01246 (best 1.01246), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10994/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 0.87524 (best 0.87524), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10994/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 0.75436 (best 0.75436), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10994/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 0.73605 (best 0.73605), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10994/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' was not in top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 0.60621 (best 0.60621), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10994/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 0.43853 (best 0.43853), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10994/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' was not in top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 0.40573 (best 0.40573), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10994/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 0.31419 (best 0.31419), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10994/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 0.30729 (best 0.30729), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10994/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 0.24998 (best 0.24998), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10994/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 0.15714 (best 0.15714), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10994/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 0.11549 (best 0.11549), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10994/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 0.07404 (best 0.07404), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10994/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 0.06753 (best 0.06753), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10994/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 0.04928 (best 0.04928), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10994/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 0.02146 (best 0.02146), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10994/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached -0.13900 (best -0.13900), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10994/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached -0.14751 (best -0.14751), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10994/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached -0.17847 (best -0.17847), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10994/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached -0.18979 (best -0.18979), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10994/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached -0.27886 (best -0.27886), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10994/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached -0.40432 (best -0.40432), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10994/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached -0.47807 (best -0.47807), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10994/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' reached -0.49499 (best -0.49499), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10994/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached -0.50009 (best -0.50009), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10994/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached -0.53513 (best -0.53513), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10994/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 7292.81it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:15:30.304302 Saving...\n",
      "2024-08-15 12:15:31.340789 38 / 83 147955\n",
      "2024-08-15 12:15:31.586025 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 5773.41it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "337250649426443fac22fff60e07e31a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 4.82347 (best 4.82347), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10996/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 3.94630 (best 3.94630), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10996/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 3.80591 (best 3.80591), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10996/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 3.67085 (best 3.67085), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10996/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 3.57945 (best 3.57945), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10996/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 3.47756 (best 3.47756), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10996/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 3.36028 (best 3.36028), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10996/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 3.29388 (best 3.29388), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10996/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 3.20641 (best 3.20641), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10996/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 3.15264 (best 3.15264), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10996/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 3.03143 (best 3.03143), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10996/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' was not in top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 2.97807 (best 2.97807), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10996/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 2.85078 (best 2.85078), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10996/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' was not in top 1\n",
      "Epoch 15, global step 800: 'train_loss' was not in top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 2.65977 (best 2.65977), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10996/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 2.60271 (best 2.60271), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10996/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 2.53202 (best 2.53202), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10996/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached 2.44376 (best 2.44376), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10996/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 2.38050 (best 2.38050), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10996/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 2.33489 (best 2.33489), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10996/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached 2.30475 (best 2.30475), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10996/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' reached 2.30063 (best 2.30063), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10996/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 2.23598 (best 2.23598), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10996/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached 2.16256 (best 2.16256), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10996/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached 2.11684 (best 2.11684), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10996/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached 2.11561 (best 2.11561), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10996/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached 2.06384 (best 2.06384), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10996/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached 2.00909 (best 2.00909), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10996/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached 1.99270 (best 1.99270), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10996/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached 1.88846 (best 1.88846), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10996/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached 1.87528 (best 1.87528), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10996/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached 1.82541 (best 1.82541), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10996/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 3514.02it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:17:01.147318 39 / 83 150464\n",
      "2024-08-15 12:17:01.317393 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 4971.92it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c17da513be46088b106db085e8347f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 1.39047 (best 1.39047), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10998/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 0.76935 (best 0.76935), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10998/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 0.66350 (best 0.66350), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10998/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 0.56102 (best 0.56102), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10998/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 0.48665 (best 0.48665), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10998/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 0.37401 (best 0.37401), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10998/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 0.22342 (best 0.22342), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10998/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 0.16058 (best 0.16058), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10998/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 0.06929 (best 0.06929), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10998/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached -0.09629 (best -0.09629), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10998/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached -0.15645 (best -0.15645), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10998/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' was not in top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached -0.17124 (best -0.17124), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10998/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached -0.40567 (best -0.40567), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10998/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' was not in top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached -0.60743 (best -0.60743), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10998/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached -0.68139 (best -0.68139), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10998/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached -0.74983 (best -0.74983), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10998/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached -0.96367 (best -0.96367), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10998/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached -1.02923 (best -1.02923), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10998/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached -1.06168 (best -1.06168), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10998/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached -1.13118 (best -1.13118), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10998/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached -1.14879 (best -1.14879), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10998/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached -1.27503 (best -1.27503), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10998/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached -1.32228 (best -1.32228), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10998/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached -1.39334 (best -1.39334), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10998/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached -1.41071 (best -1.41071), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10998/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' reached -1.43413 (best -1.43413), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10998/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' reached -1.48163 (best -1.48163), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10998/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached -1.48886 (best -1.48886), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10998/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached -1.55620 (best -1.55620), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10998/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached -1.56056 (best -1.56056), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10998/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached -1.57651 (best -1.57651), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_10998/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 5145.72it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:18:28.578507 Saving...\n",
      "2024-08-15 12:18:29.673877 40 / 83 156470\n",
      "2024-08-15 12:18:29.914221 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 7976.76it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a871ada7d5c04fa6ba32c1d804c552be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 3.75239 (best 3.75239), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11000/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 3.02177 (best 3.02177), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11000/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 2.82487 (best 2.82487), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11000/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 2.69610 (best 2.69610), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11000/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 2.54727 (best 2.54727), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11000/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 2.42383 (best 2.42383), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11000/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 2.30027 (best 2.30027), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11000/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 2.27927 (best 2.27927), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11000/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 2.13488 (best 2.13488), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11000/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 2.04425 (best 2.04425), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11000/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' was not in top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 1.93310 (best 1.93310), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11000/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' was not in top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 1.84913 (best 1.84913), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11000/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 1.74895 (best 1.74895), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11000/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 1.67410 (best 1.67410), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11000/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 1.63520 (best 1.63520), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11000/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 1.51388 (best 1.51388), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11000/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 1.45107 (best 1.45107), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11000/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 1.35031 (best 1.35031), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11000/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 1.25889 (best 1.25889), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11000/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached 1.16450 (best 1.16450), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11000/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' reached 1.14635 (best 1.14635), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11000/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached 1.02824 (best 1.02824), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11000/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached 1.02128 (best 1.02128), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11000/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' reached 1.00663 (best 1.00663), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11000/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached 0.88455 (best 0.88455), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11000/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 0.86289 (best 0.86289), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11000/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached 0.84244 (best 0.84244), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11000/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 2900.92it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:19:58.738419 41 / 83 160294\n",
      "2024-08-15 12:19:58.918096 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 4981.23it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "370978c14a5d414183119107d5c16274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 3.79354 (best 3.79354), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11002/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 2.97263 (best 2.97263), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11002/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 2.79990 (best 2.79990), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11002/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 2.69240 (best 2.69240), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11002/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 2.53133 (best 2.53133), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11002/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 2.38024 (best 2.38024), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11002/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' was not in top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 2.20918 (best 2.20918), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11002/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' was not in top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 2.00260 (best 2.00260), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11002/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' was not in top 1\n",
      "Epoch 11, global step 600: 'train_loss' was not in top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 1.98824 (best 1.98824), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11002/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 1.92612 (best 1.92612), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11002/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 1.74204 (best 1.74204), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11002/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' was not in top 1\n",
      "Epoch 16, global step 850: 'train_loss' was not in top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 1.61977 (best 1.61977), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11002/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 1.59337 (best 1.59337), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11002/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 1.56253 (best 1.56253), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11002/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 1.55744 (best 1.55744), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11002/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 1.54059 (best 1.54059), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11002/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached 1.46195 (best 1.46195), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11002/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 1.38325 (best 1.38325), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11002/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached 1.32561 (best 1.32561), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11002/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 1.32221 (best 1.32221), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11002/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' reached 1.21446 (best 1.21446), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11002/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 1.20158 (best 1.20158), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11002/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached 1.08777 (best 1.08777), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11002/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached 1.08021 (best 1.08021), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11002/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached 1.00012 (best 1.00012), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11002/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached 0.95509 (best 0.95509), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11002/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 5785.16it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:21:28.604495 Saving...\n",
      "2024-08-15 12:21:29.759060 42 / 83 162294\n",
      "2024-08-15 12:21:29.924737 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 6879.37it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9699f249921c4a18be8dc48f2aac9cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 1.87270 (best 1.87270), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11004/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 1.13766 (best 1.13766), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11004/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 0.92299 (best 0.92299), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11004/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 0.85097 (best 0.85097), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11004/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 0.70580 (best 0.70580), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11004/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' was not in top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 0.69254 (best 0.69254), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11004/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 0.54299 (best 0.54299), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11004/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 0.43001 (best 0.43001), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11004/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 0.31023 (best 0.31023), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11004/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 0.23546 (best 0.23546), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11004/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' was not in top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 0.19264 (best 0.19264), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11004/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' was not in top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 0.12831 (best 0.12831), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11004/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 0.05942 (best 0.05942), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11004/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 0.03226 (best 0.03226), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11004/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 0.01958 (best 0.01958), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11004/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached -0.09607 (best -0.09607), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11004/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached -0.16444 (best -0.16444), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11004/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached -0.17214 (best -0.17214), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11004/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached -0.23829 (best -0.23829), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11004/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached -0.25685 (best -0.25685), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11004/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached -0.27427 (best -0.27427), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11004/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached -0.34549 (best -0.34549), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11004/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached -0.34813 (best -0.34813), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11004/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached -0.42364 (best -0.42364), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11004/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached -0.47363 (best -0.47363), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11004/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached -0.53063 (best -0.53063), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11004/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' reached -0.61203 (best -0.61203), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11004/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached -0.62214 (best -0.62214), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11004/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached -0.68382 (best -0.68382), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11004/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 8696.43it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:22:59.929387 43 / 83 164573\n",
      "2024-08-15 12:23:00.165947 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 3905.82it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1922b53a4f1949c1b22165c7b8f6b356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 5.07837 (best 5.07837), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11006/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 4.49961 (best 4.49961), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11006/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 4.35924 (best 4.35924), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11006/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 4.21884 (best 4.21884), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11006/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 4.08231 (best 4.08231), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11006/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 4.02618 (best 4.02618), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11006/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' was not in top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 3.87894 (best 3.87894), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11006/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 3.80738 (best 3.80738), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11006/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 3.68510 (best 3.68510), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11006/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 3.67879 (best 3.67879), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11006/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' was not in top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 3.50001 (best 3.50001), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11006/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' was not in top 1\n",
      "Epoch 14, global step 750: 'train_loss' was not in top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 3.31822 (best 3.31822), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11006/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' was not in top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 3.26510 (best 3.26510), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11006/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 3.23332 (best 3.23332), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11006/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 3.10812 (best 3.10812), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11006/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 3.07379 (best 3.07379), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11006/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached 3.03711 (best 3.03711), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11006/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 3.02540 (best 3.02540), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11006/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 2.99768 (best 2.99768), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11006/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 2.94382 (best 2.94382), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11006/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached 2.88762 (best 2.88762), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11006/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 2.82806 (best 2.82806), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11006/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached 2.79605 (best 2.79605), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11006/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached 2.79488 (best 2.79488), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11006/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached 2.74801 (best 2.74801), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11006/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 2.62859 (best 2.62859), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11006/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached 2.62502 (best 2.62502), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11006/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' reached 2.54325 (best 2.54325), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11006/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached 2.53373 (best 2.53373), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11006/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' reached 2.52251 (best 2.52251), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11006/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached 2.52053 (best 2.52053), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11006/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached 2.46319 (best 2.46319), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11006/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached 2.39672 (best 2.39672), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11006/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached 2.32167 (best 2.32167), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11006/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 6895.23it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:24:31.457824 Saving...\n",
      "2024-08-15 12:24:32.618751 44 / 83 166003\n",
      "2024-08-15 12:24:32.784218 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 8335.43it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31bec3f34a8b47eea3c599bf0f9130eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 6.15992 (best 6.15992), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11008/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 5.70633 (best 5.70633), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11008/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 5.55267 (best 5.55267), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11008/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 5.32205 (best 5.32205), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11008/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 5.19350 (best 5.19350), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11008/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 4.95310 (best 4.95310), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11008/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 4.84372 (best 4.84372), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11008/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 4.73205 (best 4.73205), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11008/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 4.68904 (best 4.68904), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11008/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 4.60356 (best 4.60356), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11008/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 4.46227 (best 4.46227), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11008/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 4.37685 (best 4.37685), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11008/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 4.24399 (best 4.24399), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11008/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' was not in top 1\n",
      "Epoch 14, global step 750: 'train_loss' was not in top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 4.15185 (best 4.15185), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11008/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' was not in top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 4.01600 (best 4.01600), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11008/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 3.96537 (best 3.96537), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11008/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached 3.85786 (best 3.85786), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11008/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 3.84274 (best 3.84274), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11008/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 3.82306 (best 3.82306), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11008/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 3.78351 (best 3.78351), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11008/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached 3.67813 (best 3.67813), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11008/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached 3.58347 (best 3.58347), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11008/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 3.50525 (best 3.50525), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11008/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached 3.43191 (best 3.43191), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11008/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached 3.38671 (best 3.38671), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11008/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 3.24824 (best 3.24824), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11008/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached 3.23051 (best 3.23051), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11008/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 6898.08it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:26:01.582280 45 / 83 167382\n",
      "2024-08-15 12:26:01.741530 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 8135.10it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47032358c0164f8a93e36c9305dacafd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 0.01074 (best 0.01074), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11009/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached -0.61543 (best -0.61543), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11009/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached -0.76176 (best -0.76176), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11009/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached -0.82818 (best -0.82818), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11009/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached -1.00841 (best -1.00841), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11009/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' was not in top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached -1.15581 (best -1.15581), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11009/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached -1.28668 (best -1.28668), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11009/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached -1.39004 (best -1.39004), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11009/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached -1.49969 (best -1.49969), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11009/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached -1.61030 (best -1.61030), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11009/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' was not in top 1\n",
      "Epoch 12, global step 650: 'train_loss' was not in top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached -1.64060 (best -1.64060), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11009/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' was not in top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached -1.79993 (best -1.79993), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11009/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached -1.90612 (best -1.90612), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11009/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached -2.05621 (best -2.05621), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11009/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached -2.09693 (best -2.09693), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11009/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached -2.19463 (best -2.19463), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11009/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached -2.19594 (best -2.19594), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11009/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached -2.31579 (best -2.31579), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11009/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached -2.36672 (best -2.36672), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11009/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' reached -2.44426 (best -2.44426), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11009/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached -2.54703 (best -2.54703), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11009/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' reached -2.55035 (best -2.55035), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11009/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached -2.64819 (best -2.64819), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11009/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached -2.65718 (best -2.65718), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11009/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' reached -2.71023 (best -2.71023), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11009/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached -2.71707 (best -2.71707), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11009/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached -2.72431 (best -2.72431), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11009/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 7977.86it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:27:30.910488 Saving...\n",
      "2024-08-15 12:27:32.079887 46 / 83 168752\n",
      "2024-08-15 12:27:32.234794 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 8837.39it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94a4054ccbb4ee9b5146c0e0065571c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 5.14449 (best 5.14449), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11011/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 4.58070 (best 4.58070), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11011/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 4.40339 (best 4.40339), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11011/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 4.24212 (best 4.24212), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11011/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 4.16339 (best 4.16339), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11011/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 4.00341 (best 4.00341), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11011/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 3.99716 (best 3.99716), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11011/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 3.87805 (best 3.87805), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11011/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' was not in top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 3.76188 (best 3.76188), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11011/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' was not in top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 3.67398 (best 3.67398), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11011/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 3.57668 (best 3.57668), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11011/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' was not in top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 3.42860 (best 3.42860), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11011/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' was not in top 1\n",
      "Epoch 16, global step 850: 'train_loss' was not in top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 3.30642 (best 3.30642), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11011/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 3.29950 (best 3.29950), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11011/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 3.22136 (best 3.22136), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11011/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 3.13790 (best 3.13790), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11011/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 3.06728 (best 3.06728), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11011/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 3.00814 (best 3.00814), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11011/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached 2.85545 (best 2.85545), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11011/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 2.84281 (best 2.84281), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11011/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' reached 2.84266 (best 2.84266), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11011/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached 2.78017 (best 2.78017), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11011/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached 2.71159 (best 2.71159), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11011/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' reached 2.68759 (best 2.68759), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11011/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached 2.64127 (best 2.64127), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11011/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached 2.58408 (best 2.58408), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11011/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 2.53690 (best 2.53690), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11011/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached 2.52998 (best 2.52998), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11011/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' reached 2.48962 (best 2.48962), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11011/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached 2.47409 (best 2.47409), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11011/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 8256.78it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:29:03.431653 47 / 83 179110\n",
      "2024-08-15 12:29:03.686400 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 2026.73it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a2ed48e0dd64c5e8aa36f8a6a5e4412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 2.27834 (best 2.27834), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11013/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 1.76132 (best 1.76132), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11013/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 1.62669 (best 1.62669), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11013/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 1.50521 (best 1.50521), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11013/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 1.43031 (best 1.43031), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11013/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 1.27486 (best 1.27486), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11013/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 1.11092 (best 1.11092), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11013/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 1.03769 (best 1.03769), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11013/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' was not in top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 0.85434 (best 0.85434), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11013/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 0.73429 (best 0.73429), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11013/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 0.71734 (best 0.71734), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11013/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 0.65591 (best 0.65591), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11013/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' was not in top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 0.55047 (best 0.55047), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11013/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 0.44075 (best 0.44075), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11013/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 0.36493 (best 0.36493), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11013/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 0.35504 (best 0.35504), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11013/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 0.32073 (best 0.32073), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11013/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 0.18436 (best 0.18436), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11013/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached 0.17441 (best 0.17441), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11013/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 0.17430 (best 0.17430), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11013/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 0.10354 (best 0.10354), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11013/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 0.06247 (best 0.06247), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11013/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached -0.02299 (best -0.02299), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11013/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached -0.07154 (best -0.07154), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11013/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached -0.08146 (best -0.08146), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11013/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached -0.12968 (best -0.12968), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11013/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached -0.23963 (best -0.23963), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11013/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached -0.24113 (best -0.24113), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11013/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' reached -0.31284 (best -0.31284), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11013/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached -0.34117 (best -0.34117), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11013/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached -0.35563 (best -0.35563), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11013/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached -0.38096 (best -0.38096), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11013/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 6657.04it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:30:33.788694 Saving...\n",
      "2024-08-15 12:30:36.236872 48 / 83 182643\n",
      "2024-08-15 12:30:36.407716 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 6088.07it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "139c305ed7834af180e059ab5dad6ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 2.19706 (best 2.19706), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11015/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 1.60851 (best 1.60851), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11015/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 1.38568 (best 1.38568), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11015/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 1.33826 (best 1.33826), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11015/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 1.15375 (best 1.15375), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11015/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 1.12431 (best 1.12431), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11015/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 0.90635 (best 0.90635), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11015/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 0.85951 (best 0.85951), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11015/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 0.71366 (best 0.71366), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11015/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' was not in top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 0.64300 (best 0.64300), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11015/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 0.54518 (best 0.54518), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11015/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' was not in top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 0.46036 (best 0.46036), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11015/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 0.36370 (best 0.36370), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11015/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' was not in top 1\n",
      "Epoch 16, global step 850: 'train_loss' was not in top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 0.35234 (best 0.35234), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11015/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 0.25597 (best 0.25597), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11015/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 0.21938 (best 0.21938), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11015/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 0.15835 (best 0.15835), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11015/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 0.13604 (best 0.13604), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11015/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached 0.01884 (best 0.01884), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11015/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached -0.00854 (best -0.00854), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11015/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached -0.15140 (best -0.15140), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11015/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached -0.21175 (best -0.21175), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11015/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' reached -0.27951 (best -0.27951), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11015/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached -0.33478 (best -0.33478), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11015/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached -0.42297 (best -0.42297), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11015/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' reached -0.43331 (best -0.43331), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11015/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached -0.43672 (best -0.43672), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11015/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached -0.47674 (best -0.47674), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11015/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached -0.49416 (best -0.49416), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11015/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' reached -0.51849 (best -0.51849), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11015/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached -0.56591 (best -0.56591), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11015/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 3889.49it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:32:04.207775 49 / 83 186253\n",
      "2024-08-15 12:32:04.408393 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 9083.08it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611aa063549f4574b9fbb74a95e774fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 3.31410 (best 3.31410), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 2.60670 (best 2.60670), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 2.43016 (best 2.43016), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 2.24383 (best 2.24383), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 2.14722 (best 2.14722), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 2.03371 (best 2.03371), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 1.93966 (best 1.93966), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 1.91667 (best 1.91667), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 1.85464 (best 1.85464), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 1.68926 (best 1.68926), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 1.66566 (best 1.66566), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 1.59975 (best 1.59975), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 1.50108 (best 1.50108), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 1.47504 (best 1.47504), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 1.37420 (best 1.37420), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 1.36213 (best 1.36213), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 1.23753 (best 1.23753), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 1.21423 (best 1.21423), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 1.15863 (best 1.15863), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 1.10851 (best 1.10851), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 0.99829 (best 0.99829), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 0.93229 (best 0.93229), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached 0.88248 (best 0.88248), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached 0.84150 (best 0.84150), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' reached 0.81638 (best 0.81638), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 0.72331 (best 0.72331), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached 0.71922 (best 0.71922), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached 0.71144 (best 0.71144), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' reached 0.69039 (best 0.69039), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached 0.65582 (best 0.65582), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' reached 0.60910 (best 0.60910), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached 0.56920 (best 0.56920), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached 0.56277 (best 0.56277), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 0.51742 (best 0.51742), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' reached 0.49586 (best 0.49586), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11017/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 6585.91it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:33:34.118593 Saving...\n",
      "2024-08-15 12:33:35.487531 50 / 83 188704\n",
      "2024-08-15 12:33:35.652671 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 4966.92it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdefafc8fc4845ecbae73f14fb5a5439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 3.95281 (best 3.95281), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11019/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 3.34564 (best 3.34564), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11019/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 3.25806 (best 3.25806), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11019/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 3.08733 (best 3.08733), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11019/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 3.00413 (best 3.00413), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11019/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 2.86875 (best 2.86875), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11019/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 2.84606 (best 2.84606), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11019/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 2.72119 (best 2.72119), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11019/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 2.63003 (best 2.63003), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11019/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 2.61836 (best 2.61836), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11019/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 2.50675 (best 2.50675), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11019/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 2.48888 (best 2.48888), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11019/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 2.35996 (best 2.35996), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11019/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 2.33377 (best 2.33377), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11019/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 2.27080 (best 2.27080), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11019/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' was not in top 1\n",
      "Epoch 16, global step 850: 'train_loss' was not in top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 2.25622 (best 2.25622), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11019/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 2.09146 (best 2.09146), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11019/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 2.03190 (best 2.03190), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11019/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 1.95576 (best 1.95576), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11019/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached 1.87650 (best 1.87650), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11019/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached 1.72382 (best 1.72382), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11019/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 1.72130 (best 1.72130), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11019/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 1.71473 (best 1.71473), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11019/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached 1.61076 (best 1.61076), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11019/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached 1.60847 (best 1.60847), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11019/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' reached 1.56118 (best 1.56118), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11019/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached 1.51116 (best 1.51116), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11019/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached 1.48054 (best 1.48054), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11019/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached 1.47999 (best 1.47999), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11019/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 1.44512 (best 1.44512), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11019/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached 1.44061 (best 1.44061), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11019/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 4734.37it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:35:03.029640 51 / 83 189891\n",
      "2024-08-15 12:35:03.201993 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 4992.36it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed7e0ef2e4b24ceca9141f35e39bfa8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 5.87543 (best 5.87543), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 5.34829 (best 5.34829), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 5.12865 (best 5.12865), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 4.92100 (best 4.92100), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 4.83752 (best 4.83752), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 4.64437 (best 4.64437), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 4.55835 (best 4.55835), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 4.50015 (best 4.50015), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 4.42531 (best 4.42531), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' was not in top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 4.28553 (best 4.28553), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 4.21359 (best 4.21359), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 4.14573 (best 4.14573), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 4.13938 (best 4.13938), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 4.08966 (best 4.08966), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 4.08573 (best 4.08573), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 3.97934 (best 3.97934), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 3.95330 (best 3.95330), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 3.89203 (best 3.89203), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 3.88004 (best 3.88004), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 3.76505 (best 3.76505), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 3.67922 (best 3.67922), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached 3.64796 (best 3.64796), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 3.62319 (best 3.62319), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached 3.57852 (best 3.57852), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 3.52076 (best 3.52076), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' reached 3.49590 (best 3.49590), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached 3.45665 (best 3.45665), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached 3.38641 (best 3.38641), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached 3.35980 (best 3.35980), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' reached 3.33525 (best 3.33525), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached 3.29598 (best 3.29598), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 3.29450 (best 3.29450), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached 3.28582 (best 3.28582), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' reached 3.27452 (best 3.27452), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached 3.23171 (best 3.23171), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11021/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 6743.86it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:36:29.019080 Saving...\n",
      "2024-08-15 12:36:31.809650 52 / 83 212192\n",
      "2024-08-15 12:36:32.043711 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 4209.54it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cbb8f1f0b9c4398824e062faa721ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 2.89449 (best 2.89449), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11023/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 2.23793 (best 2.23793), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11023/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 2.03069 (best 2.03069), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11023/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 1.84615 (best 1.84615), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11023/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 1.78352 (best 1.78352), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11023/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 1.67251 (best 1.67251), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11023/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 1.59738 (best 1.59738), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11023/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 1.48974 (best 1.48974), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11023/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 1.34369 (best 1.34369), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11023/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 1.29944 (best 1.29944), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11023/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 1.21621 (best 1.21621), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11023/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 1.13334 (best 1.13334), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11023/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 1.08838 (best 1.08838), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11023/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 1.05672 (best 1.05672), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11023/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 0.96599 (best 0.96599), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11023/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 0.87646 (best 0.87646), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11023/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' was not in top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 0.78088 (best 0.78088), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11023/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 0.72189 (best 0.72189), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11023/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 0.66740 (best 0.66740), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11023/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 0.65142 (best 0.65142), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11023/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached 0.59823 (best 0.59823), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11023/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 0.56179 (best 0.56179), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11023/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached 0.47300 (best 0.47300), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11023/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached 0.44506 (best 0.44506), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11023/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 0.35929 (best 0.35929), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11023/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached 0.35561 (best 0.35561), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11023/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached 0.31246 (best 0.31246), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11023/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached 0.23970 (best 0.23970), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11023/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached 0.19753 (best 0.19753), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11023/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached 0.14020 (best 0.14020), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11023/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached 0.11886 (best 0.11886), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11023/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 0.05579 (best 0.05579), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11023/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 5178.69it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:37:59.501812 53 / 83 215885\n",
      "2024-08-15 12:37:59.753576 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 7256.23it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46c03dd5ab82462491dba67aea2fb4d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 0.70662 (best 0.70662), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11025/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 0.23181 (best 0.23181), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11025/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached -0.05973 (best -0.05973), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11025/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached -0.28038 (best -0.28038), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11025/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached -0.44994 (best -0.44994), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11025/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached -0.60894 (best -0.60894), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11025/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached -0.76827 (best -0.76827), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11025/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached -0.88223 (best -0.88223), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11025/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached -0.91226 (best -0.91226), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11025/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached -1.00741 (best -1.00741), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11025/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' was not in top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached -1.18327 (best -1.18327), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11025/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached -1.25363 (best -1.25363), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11025/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached -1.29814 (best -1.29814), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11025/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' was not in top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached -1.32066 (best -1.32066), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11025/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached -1.33578 (best -1.33578), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11025/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached -1.49008 (best -1.49008), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11025/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached -1.50297 (best -1.50297), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11025/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached -1.57290 (best -1.57290), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11025/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached -1.62335 (best -1.62335), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11025/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached -1.63441 (best -1.63441), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11025/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached -1.67631 (best -1.67631), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11025/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached -1.77305 (best -1.77305), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11025/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached -1.82070 (best -1.82070), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11025/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached -1.84096 (best -1.84096), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11025/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached -1.87277 (best -1.87277), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11025/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached -1.95184 (best -1.95184), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11025/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached -1.96307 (best -1.96307), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11025/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached -1.96811 (best -1.96811), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11025/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached -2.03225 (best -2.03225), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11025/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached -2.05432 (best -2.05432), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11025/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached -2.07810 (best -2.07810), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11025/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached -2.10031 (best -2.10031), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11025/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached -2.10614 (best -2.10614), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11025/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 4650.70it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:39:28.669840 Saving...\n",
      "2024-08-15 12:39:31.725648 54 / 83 216589\n",
      "2024-08-15 12:39:32.054346 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 7698.97it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1547460bab964d1e986f96d394b3cdfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 3.68919 (best 3.68919), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11027/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 2.95908 (best 2.95908), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11027/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 2.72835 (best 2.72835), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11027/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 2.71535 (best 2.71535), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11027/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 2.52624 (best 2.52624), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11027/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 2.38449 (best 2.38449), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11027/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' was not in top 1\n",
      "Epoch 7, global step 400: 'train_loss' was not in top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 2.15758 (best 2.15758), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11027/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' was not in top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 2.05395 (best 2.05395), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11027/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' was not in top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 1.98264 (best 1.98264), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11027/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' was not in top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 1.84500 (best 1.84500), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11027/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 1.81986 (best 1.81986), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11027/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 1.75861 (best 1.75861), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11027/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 1.72463 (best 1.72463), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11027/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 1.70392 (best 1.70392), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11027/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 1.67439 (best 1.67439), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11027/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached 1.60477 (best 1.60477), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11027/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 1.57009 (best 1.57009), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11027/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 1.48075 (best 1.48075), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11027/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached 1.38392 (best 1.38392), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11027/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 1.33491 (best 1.33491), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11027/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 1.29284 (best 1.29284), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11027/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached 1.23873 (best 1.23873), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11027/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached 1.23683 (best 1.23683), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11027/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached 1.22743 (best 1.22743), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11027/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached 1.20711 (best 1.20711), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11027/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached 1.09241 (best 1.09241), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11027/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached 1.04475 (best 1.04475), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11027/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached 1.01782 (best 1.01782), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11027/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 6937.86it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:41:03.923989 55 / 83 216816\n",
      "2024-08-15 12:41:04.103709 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 3823.35it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6940283e11d04b8db221a90b1bdfc92c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 4.12202 (best 4.12202), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11029/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 3.42201 (best 3.42201), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11029/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 3.16730 (best 3.16730), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11029/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 3.01770 (best 3.01770), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11029/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 2.94873 (best 2.94873), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11029/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 2.85258 (best 2.85258), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11029/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 2.73799 (best 2.73799), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11029/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 2.71475 (best 2.71475), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11029/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 2.56914 (best 2.56914), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11029/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 2.51908 (best 2.51908), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11029/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 2.41544 (best 2.41544), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11029/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 2.38252 (best 2.38252), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11029/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 2.37157 (best 2.37157), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11029/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 2.31599 (best 2.31599), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11029/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 2.28137 (best 2.28137), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11029/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 2.12564 (best 2.12564), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11029/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' was not in top 1\n",
      "Epoch 17, global step 900: 'train_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 2.04038 (best 2.04038), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11029/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 2.03266 (best 2.03266), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11029/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 2.01521 (best 2.01521), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11029/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 1.92241 (best 1.92241), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11029/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 1.88921 (best 1.88921), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11029/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached 1.79504 (best 1.79504), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11029/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached 1.78405 (best 1.78405), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11029/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached 1.71573 (best 1.71573), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11029/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 1.64548 (best 1.64548), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11029/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' reached 1.63436 (best 1.63436), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11029/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached 1.59371 (best 1.59371), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11029/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached 1.50229 (best 1.50229), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11029/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached 1.46019 (best 1.46019), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11029/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 1.45622 (best 1.45622), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11029/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached 1.36693 (best 1.36693), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11029/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached 1.34303 (best 1.34303), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11029/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 8400.53it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:42:33.522046 Saving...\n",
      "2024-08-15 12:42:36.095241 56 / 83 216947\n",
      "2024-08-15 12:42:36.415563 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 7188.22it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5945d3665fc4443cab253dbd0472f161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 2.39400 (best 2.39400), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11031/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 1.77418 (best 1.77418), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11031/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 1.51253 (best 1.51253), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11031/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 1.38615 (best 1.38615), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11031/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 1.16462 (best 1.16462), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11031/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' was not in top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 0.94678 (best 0.94678), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11031/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 0.85170 (best 0.85170), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11031/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' was not in top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 0.80539 (best 0.80539), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11031/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 0.70983 (best 0.70983), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11031/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 0.65001 (best 0.65001), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11031/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' was not in top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 0.64721 (best 0.64721), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11031/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 0.58361 (best 0.58361), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11031/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 0.48048 (best 0.48048), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11031/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 0.46435 (best 0.46435), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11031/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 0.45186 (best 0.45186), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11031/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 0.37114 (best 0.37114), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11031/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 0.30134 (best 0.30134), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11031/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 0.25413 (best 0.25413), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11031/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 0.17968 (best 0.17968), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11031/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 0.10099 (best 0.10099), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11031/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached 0.09123 (best 0.09123), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11031/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached 0.01784 (best 0.01784), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11031/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 0.01176 (best 0.01176), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11031/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached -0.02085 (best -0.02085), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11031/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached -0.10234 (best -0.10234), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11031/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached -0.13028 (best -0.13028), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11031/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' reached -0.15670 (best -0.15670), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11031/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached -0.19418 (best -0.19418), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11031/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached -0.19441 (best -0.19441), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11031/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached -0.24144 (best -0.24144), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11031/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' reached -0.28658 (best -0.28658), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11031/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached -0.31859 (best -0.31859), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11031/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 3859.68it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:44:03.800976 57 / 83 217110\n",
      "2024-08-15 12:44:03.965503 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 3939.39it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e040c61a5bc14d888a81bbd9758de8d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 2.61700 (best 2.61700), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11033/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 1.99985 (best 1.99985), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11033/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 1.74097 (best 1.74097), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11033/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 1.65891 (best 1.65891), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11033/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 1.54328 (best 1.54328), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11033/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 1.49730 (best 1.49730), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11033/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 1.47494 (best 1.47494), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11033/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 1.37611 (best 1.37611), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11033/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' was not in top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 1.32888 (best 1.32888), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11033/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 1.24947 (best 1.24947), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11033/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 1.17568 (best 1.17568), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11033/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 1.17022 (best 1.17022), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11033/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 1.10836 (best 1.10836), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11033/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 1.07221 (best 1.07221), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11033/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 1.03542 (best 1.03542), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11033/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 0.97660 (best 0.97660), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11033/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 0.96538 (best 0.96538), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11033/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 0.82584 (best 0.82584), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11033/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 0.80286 (best 0.80286), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11033/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 0.76414 (best 0.76414), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11033/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 0.69856 (best 0.69856), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11033/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 0.65211 (best 0.65211), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11033/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached 0.58722 (best 0.58722), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11033/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 0.54565 (best 0.54565), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11033/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 0.51192 (best 0.51192), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11033/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached 0.44638 (best 0.44638), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11033/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached 0.39610 (best 0.39610), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11033/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' reached 0.39215 (best 0.39215), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11033/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached 0.31514 (best 0.31514), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11033/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 0.30506 (best 0.30506), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11033/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' reached 0.21958 (best 0.21958), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11033/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached 0.19099 (best 0.19099), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11033/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 6955.73it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:45:31.569320 Saving...\n",
      "2024-08-15 12:45:34.091914 58 / 83 221792\n",
      "2024-08-15 12:45:34.410813 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 6008.12it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa63bdd589ff46cbaad7fc56fddf39eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 3.62220 (best 3.62220), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11035/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 2.81570 (best 2.81570), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11035/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 2.61940 (best 2.61940), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11035/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 2.47134 (best 2.47134), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11035/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 2.34014 (best 2.34014), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11035/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 2.19331 (best 2.19331), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11035/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 2.19046 (best 2.19046), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11035/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 1.97695 (best 1.97695), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11035/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 1.83783 (best 1.83783), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11035/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 1.75884 (best 1.75884), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11035/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 1.71038 (best 1.71038), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11035/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 1.63365 (best 1.63365), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11035/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 1.61033 (best 1.61033), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11035/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 1.53553 (best 1.53553), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11035/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 1.49484 (best 1.49484), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11035/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 1.41522 (best 1.41522), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11035/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' was not in top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 1.41446 (best 1.41446), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11035/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 1.35333 (best 1.35333), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11035/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 1.27546 (best 1.27546), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11035/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 1.20092 (best 1.20092), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11035/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 1.18565 (best 1.18565), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11035/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 1.11825 (best 1.11825), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11035/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached 1.08099 (best 1.08099), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11035/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached 1.07256 (best 1.07256), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11035/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 0.96957 (best 0.96957), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11035/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached 0.94532 (best 0.94532), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11035/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached 0.88965 (best 0.88965), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11035/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' reached 0.82462 (best 0.82462), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11035/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 0.79350 (best 0.79350), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11035/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached 0.75365 (best 0.75365), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11035/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached 0.74211 (best 0.74211), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11035/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 6208.18it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:47:02.190997 59 / 83 245267\n",
      "2024-08-15 12:47:02.381569 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 5957.87it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6acfe3cfba1e4dffabf78ff91413d1a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 3.64923 (best 3.64923), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11037/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 2.71479 (best 2.71479), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11037/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 2.35923 (best 2.35923), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11037/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 2.35208 (best 2.35208), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11037/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 2.05091 (best 2.05091), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11037/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' was not in top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 1.79700 (best 1.79700), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11037/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' was not in top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 1.77916 (best 1.77916), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11037/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' was not in top 1\n",
      "Epoch 10, global step 550: 'train_loss' was not in top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 1.48687 (best 1.48687), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11037/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 1.38664 (best 1.38664), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11037/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' was not in top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 1.29748 (best 1.29748), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11037/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 1.27966 (best 1.27966), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11037/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 1.23675 (best 1.23675), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11037/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 1.21097 (best 1.21097), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11037/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 1.14965 (best 1.14965), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11037/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached 1.05349 (best 1.05349), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11037/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached 1.00138 (best 1.00138), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11037/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 0.96334 (best 0.96334), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11037/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached 0.89154 (best 0.89154), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11037/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 0.87857 (best 0.87857), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11037/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 0.85380 (best 0.85380), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11037/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached 0.84385 (best 0.84385), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11037/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached 0.79433 (best 0.79433), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11037/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' reached 0.74793 (best 0.74793), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11037/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached 0.74175 (best 0.74175), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11037/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' reached 0.69559 (best 0.69559), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11037/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached 0.69548 (best 0.69548), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11037/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 3767.33it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:48:29.386520 Saving...\n",
      "2024-08-15 12:48:31.022930 60 / 83 247437\n",
      "2024-08-15 12:48:31.277650 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 6704.95it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a16792937049a4b5f9a23dffa461a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 6.52210 (best 6.52210), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11039/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 5.20193 (best 5.20193), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11039/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' was not in top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 5.09518 (best 5.09518), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11039/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' was not in top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 4.82111 (best 4.82111), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11039/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 4.73221 (best 4.73221), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11039/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 4.70834 (best 4.70834), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11039/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' was not in top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 4.64417 (best 4.64417), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11039/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' was not in top 1\n",
      "Epoch 11, global step 600: 'train_loss' was not in top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 4.19302 (best 4.19302), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11039/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 4.07317 (best 4.07317), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11039/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 4.03637 (best 4.03637), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11039/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 3.97031 (best 3.97031), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11039/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 3.88646 (best 3.88646), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11039/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 3.84583 (best 3.84583), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11039/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 3.80983 (best 3.80983), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11039/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 3.77603 (best 3.77603), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11039/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 3.72744 (best 3.72744), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11039/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached 3.70349 (best 3.70349), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11039/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 3.62121 (best 3.62121), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11039/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 3.59545 (best 3.59545), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11039/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached 3.55931 (best 3.55931), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11039/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached 3.53792 (best 3.53792), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11039/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached 3.51413 (best 3.51413), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11039/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached 3.42879 (best 3.42879), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11039/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached 3.38433 (best 3.38433), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11039/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached 3.38200 (best 3.38200), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11039/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached 3.33290 (best 3.33290), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11039/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached 3.31534 (best 3.31534), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11039/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached 3.29238 (best 3.29238), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11039/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached 3.26749 (best 3.26749), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11039/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' reached 3.20330 (best 3.20330), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11039/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 7191.38it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:49:58.595188 61 / 83 250589\n",
      "2024-08-15 12:49:58.810974 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 3282.10it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5755bdc7ec5a462aaab0ddaccca16011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 5.03192 (best 5.03192), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11041/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 4.25627 (best 4.25627), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11041/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 4.07033 (best 4.07033), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11041/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 3.92224 (best 3.92224), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11041/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 3.70622 (best 3.70622), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11041/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 3.58156 (best 3.58156), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11041/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 3.51402 (best 3.51402), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11041/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 3.37148 (best 3.37148), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11041/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 3.28445 (best 3.28445), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11041/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 3.14808 (best 3.14808), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11041/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 3.11943 (best 3.11943), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11041/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 3.03318 (best 3.03318), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11041/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' was not in top 1\n",
      "Epoch 13, global step 700: 'train_loss' was not in top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 2.85624 (best 2.85624), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11041/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' was not in top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 2.77474 (best 2.77474), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11041/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 2.69695 (best 2.69695), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11041/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 2.67644 (best 2.67644), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11041/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 2.61001 (best 2.61001), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11041/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 2.58410 (best 2.58410), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11041/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached 2.51251 (best 2.51251), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11041/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 2.44667 (best 2.44667), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11041/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached 2.40266 (best 2.40266), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11041/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 2.37179 (best 2.37179), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11041/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached 2.28775 (best 2.28775), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11041/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 2.26771 (best 2.26771), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11041/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached 2.24198 (best 2.24198), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11041/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached 2.21924 (best 2.21924), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11041/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached 2.15665 (best 2.15665), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11041/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached 2.14376 (best 2.14376), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11041/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' reached 2.13487 (best 2.13487), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11041/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached 2.09054 (best 2.09054), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11041/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 2.02081 (best 2.02081), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11041/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached 1.98742 (best 1.98742), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11041/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached 1.94134 (best 1.94134), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11041/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 6762.63it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:51:29.575729 Saving...\n",
      "2024-08-15 12:51:33.143154 62 / 83 251776\n",
      "2024-08-15 12:51:33.344922 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 3568.26it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c250d6ccb3045a6b53cab4d6d052a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 2.81569 (best 2.81569), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11043/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 2.14286 (best 2.14286), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11043/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 1.94743 (best 1.94743), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11043/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 1.78472 (best 1.78472), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11043/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 1.68882 (best 1.68882), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11043/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 1.58443 (best 1.58443), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11043/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 1.45495 (best 1.45495), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11043/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 1.40024 (best 1.40024), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11043/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 1.27804 (best 1.27804), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11043/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 1.23890 (best 1.23890), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11043/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 1.14114 (best 1.14114), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11043/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' was not in top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 1.14046 (best 1.14046), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11043/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 0.94389 (best 0.94389), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11043/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' was not in top 1\n",
      "Epoch 15, global step 800: 'train_loss' was not in top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 0.87989 (best 0.87989), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11043/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 0.74289 (best 0.74289), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11043/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 0.74064 (best 0.74064), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11043/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached 0.71985 (best 0.71985), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11043/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 0.65536 (best 0.65536), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11043/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 0.60788 (best 0.60788), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11043/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached 0.53849 (best 0.53849), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11043/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached 0.51541 (best 0.51541), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11043/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 0.42193 (best 0.42193), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11043/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached 0.37995 (best 0.37995), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11043/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached 0.30093 (best 0.30093), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11043/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' reached 0.29710 (best 0.29710), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11043/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached 0.28735 (best 0.28735), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11043/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached 0.23801 (best 0.23801), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11043/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached 0.17628 (best 0.17628), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11043/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached 0.15643 (best 0.15643), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11043/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached 0.12644 (best 0.12644), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11043/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 6807.08it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:53:01.927386 63 / 83 257539\n",
      "2024-08-15 12:53:02.196579 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 4374.72it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c6cf8375a0406ca527458bc9765ff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 4.31192 (best 4.31192), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11045/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 3.57641 (best 3.57641), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11045/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 3.41498 (best 3.41498), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11045/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 3.31356 (best 3.31356), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11045/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 3.22017 (best 3.22017), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11045/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 3.05192 (best 3.05192), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11045/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 2.97500 (best 2.97500), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11045/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 2.86022 (best 2.86022), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11045/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 2.82251 (best 2.82251), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11045/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 2.70158 (best 2.70158), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11045/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 2.60000 (best 2.60000), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11045/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' was not in top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 2.55176 (best 2.55176), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11045/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 2.49013 (best 2.49013), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11045/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' was not in top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 2.44282 (best 2.44282), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11045/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' was not in top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 2.28793 (best 2.28793), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11045/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 2.20357 (best 2.20357), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11045/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 2.16233 (best 2.16233), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11045/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 2.14705 (best 2.14705), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11045/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 2.07786 (best 2.07786), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11045/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached 1.99808 (best 1.99808), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11045/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached 1.97502 (best 1.97502), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11045/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 1.89935 (best 1.89935), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11045/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached 1.85253 (best 1.85253), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11045/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached 1.77793 (best 1.77793), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11045/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached 1.68586 (best 1.68586), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11045/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 1.67760 (best 1.67760), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11045/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' reached 1.66630 (best 1.66630), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11045/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached 1.66628 (best 1.66628), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11045/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 1246.83it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:54:30.445263 Saving...\n",
      "2024-08-15 12:54:33.118915 64 / 83 260691\n",
      "2024-08-15 12:54:33.275145 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 3070.24it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ede3b889b7c4eb68e482da37c28c6cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 6.65517 (best 6.65517), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11047/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 5.94502 (best 5.94502), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11047/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 5.55985 (best 5.55985), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11047/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 5.46687 (best 5.46687), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11047/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' was not in top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 5.35005 (best 5.35005), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11047/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 5.22026 (best 5.22026), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11047/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 5.20851 (best 5.20851), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11047/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' was not in top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 5.01249 (best 5.01249), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11047/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 4.96519 (best 4.96519), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11047/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 4.91487 (best 4.91487), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11047/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 4.87688 (best 4.87688), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11047/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 4.87298 (best 4.87298), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11047/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 4.77765 (best 4.77765), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11047/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 4.64125 (best 4.64125), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11047/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' was not in top 1\n",
      "Epoch 17, global step 900: 'train_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 4.54628 (best 4.54628), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11047/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 4.48571 (best 4.48571), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11047/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 4.42428 (best 4.42428), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11047/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 4.40581 (best 4.40581), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11047/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 4.28954 (best 4.28954), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11047/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 4.26899 (best 4.26899), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11047/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached 4.15299 (best 4.15299), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11047/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached 4.04434 (best 4.04434), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11047/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached 3.99537 (best 3.99537), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11047/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' reached 3.96604 (best 3.96604), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11047/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 3.95793 (best 3.95793), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11047/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached 3.88486 (best 3.88486), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11047/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' reached 3.86161 (best 3.86161), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11047/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 7889.33it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:56:04.436400 65 / 83 275363\n",
      "2024-08-15 12:56:04.595450 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 4094.03it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0046683ad334f178662b167b652f0e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 1.27210 (best 1.27210), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11049/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 0.82373 (best 0.82373), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11049/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 0.69001 (best 0.69001), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11049/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 0.54092 (best 0.54092), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11049/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 0.40178 (best 0.40178), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11049/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 0.28202 (best 0.28202), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11049/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 0.18095 (best 0.18095), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11049/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached -0.00755 (best -0.00755), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11049/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached -0.11895 (best -0.11895), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11049/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' was not in top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached -0.31136 (best -0.31136), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11049/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' was not in top 1\n",
      "Epoch 12, global step 650: 'train_loss' was not in top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached -0.31701 (best -0.31701), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11049/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached -0.45826 (best -0.45826), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11049/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached -0.59184 (best -0.59184), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11049/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached -0.71313 (best -0.71313), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11049/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached -0.75800 (best -0.75800), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11049/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached -0.84856 (best -0.84856), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11049/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached -0.86285 (best -0.86285), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11049/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached -0.96585 (best -0.96585), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11049/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached -0.99201 (best -0.99201), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11049/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached -1.08725 (best -1.08725), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11049/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached -1.15474 (best -1.15474), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11049/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached -1.15771 (best -1.15771), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11049/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached -1.19214 (best -1.19214), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11049/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached -1.25057 (best -1.25057), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11049/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached -1.30444 (best -1.30444), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11049/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached -1.37136 (best -1.37136), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11049/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached -1.39424 (best -1.39424), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11049/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' reached -1.39891 (best -1.39891), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11049/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached -1.39974 (best -1.39974), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11049/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached -1.46053 (best -1.46053), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11049/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached -1.46405 (best -1.46405), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11049/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached -1.46478 (best -1.46478), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11049/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 8062.42it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:57:33.858207 Saving...\n",
      "2024-08-15 12:57:35.566907 66 / 83 285392\n",
      "2024-08-15 12:57:35.860476 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 5217.59it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b8f78f705f54fc691e3397c54d6a249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 2.76644 (best 2.76644), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11050/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 1.94214 (best 1.94214), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11050/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 1.80547 (best 1.80547), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11050/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 1.79702 (best 1.79702), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11050/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 1.61903 (best 1.61903), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11050/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 1.53228 (best 1.53228), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11050/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' was not in top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 1.44787 (best 1.44787), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11050/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 1.25402 (best 1.25402), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11050/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' was not in top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 1.15953 (best 1.15953), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11050/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 1.09682 (best 1.09682), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11050/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 1.05552 (best 1.05552), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11050/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 1.00003 (best 1.00003), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11050/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 0.89458 (best 0.89458), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11050/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 0.88785 (best 0.88785), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11050/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' was not in top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 0.81499 (best 0.81499), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11050/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 0.76853 (best 0.76853), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11050/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 0.65689 (best 0.65689), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11050/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached 0.64105 (best 0.64105), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11050/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 0.61208 (best 0.61208), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11050/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 0.42167 (best 0.42167), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11050/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached 0.40511 (best 0.40511), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11050/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 0.29324 (best 0.29324), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11050/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' reached 0.28467 (best 0.28467), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11050/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 0.25123 (best 0.25123), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11050/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached 0.19004 (best 0.19004), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11050/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached 0.16928 (best 0.16928), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11050/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached 0.12427 (best 0.12427), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11050/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' reached 0.08396 (best 0.08396), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11050/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' reached 0.05230 (best 0.05230), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11050/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached -0.04495 (best -0.04495), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11050/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 5400.48it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 12:59:04.398545 67 / 83 289885\n",
      "2024-08-15 12:59:04.552807 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 9119.49it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "650a3c66610e4d168374fa520ab0191a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 4.22547 (best 4.22547), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11052/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 3.68332 (best 3.68332), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11052/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 3.38489 (best 3.38489), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11052/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 3.24276 (best 3.24276), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11052/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 3.05713 (best 3.05713), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11052/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 3.01287 (best 3.01287), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11052/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 2.86053 (best 2.86053), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11052/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 2.69599 (best 2.69599), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11052/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 2.63595 (best 2.63595), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11052/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 2.56353 (best 2.56353), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11052/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 2.48189 (best 2.48189), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11052/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 2.47886 (best 2.47886), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11052/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 2.45593 (best 2.45593), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11052/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 2.29284 (best 2.29284), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11052/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' was not in top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 2.20736 (best 2.20736), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11052/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' was not in top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 2.15850 (best 2.15850), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11052/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 2.10014 (best 2.10014), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11052/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 1.97633 (best 1.97633), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11052/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 1.90884 (best 1.90884), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11052/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 1.79813 (best 1.79813), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11052/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached 1.74162 (best 1.74162), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11052/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 1.69088 (best 1.69088), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11052/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 1.68957 (best 1.68957), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11052/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached 1.64726 (best 1.64726), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11052/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached 1.60353 (best 1.60353), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11052/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached 1.59298 (best 1.59298), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11052/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' reached 1.56388 (best 1.56388), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11052/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached 1.52322 (best 1.52322), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11052/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' reached 1.50407 (best 1.50407), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11052/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached 1.50338 (best 1.50338), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11052/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' reached 1.49505 (best 1.49505), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11052/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached 1.40162 (best 1.40162), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11052/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached 1.38474 (best 1.38474), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11052/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 5275.89it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 13:00:32.721022 Saving...\n",
      "2024-08-15 13:00:34.394577 68 / 83 293104\n",
      "2024-08-15 13:00:34.633179 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 8407.68it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6907e360a144d198249d19c067a5679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 3.05014 (best 3.05014), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11054/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 2.43021 (best 2.43021), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11054/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 2.23174 (best 2.23174), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11054/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 2.10691 (best 2.10691), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11054/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 2.02948 (best 2.02948), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11054/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 1.97342 (best 1.97342), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11054/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 1.83888 (best 1.83888), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11054/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 1.76015 (best 1.76015), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11054/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 1.72532 (best 1.72532), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11054/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 1.63684 (best 1.63684), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11054/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 1.52922 (best 1.52922), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11054/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 1.44089 (best 1.44089), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11054/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 1.36770 (best 1.36770), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11054/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 1.34002 (best 1.34002), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11054/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 1.26693 (best 1.26693), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11054/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 1.24077 (best 1.24077), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11054/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 1.16350 (best 1.16350), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11054/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 1.11658 (best 1.11658), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11054/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 1.04488 (best 1.04488), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11054/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 1.04211 (best 1.04211), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11054/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 0.97425 (best 0.97425), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11054/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached 0.92709 (best 0.92709), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11054/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 0.91114 (best 0.91114), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11054/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 0.84565 (best 0.84565), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11054/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached 0.78887 (best 0.78887), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11054/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached 0.68362 (best 0.68362), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11054/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 0.61044 (best 0.61044), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11054/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached 0.54062 (best 0.54062), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11054/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached 0.53555 (best 0.53555), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11054/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached 0.50905 (best 0.50905), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11054/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached 0.44835 (best 0.44835), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11054/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached 0.40077 (best 0.40077), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11054/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 4673.74it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 13:02:07.029799 69 / 83 297206\n",
      "2024-08-15 13:02:07.287315 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 8444.18it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a57eb709d24cbe9fc7f494119f209f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 2.66945 (best 2.66945), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 2.13301 (best 2.13301), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 1.96488 (best 1.96488), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 1.80646 (best 1.80646), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 1.67605 (best 1.67605), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 1.53531 (best 1.53531), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 1.42527 (best 1.42527), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 1.33325 (best 1.33325), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 1.24697 (best 1.24697), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 1.10548 (best 1.10548), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 0.95912 (best 0.95912), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 0.92844 (best 0.92844), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 0.87120 (best 0.87120), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 0.87111 (best 0.87111), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' was not in top 1\n",
      "Epoch 15, global step 800: 'train_loss' was not in top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 0.80040 (best 0.80040), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 0.62445 (best 0.62445), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 0.57509 (best 0.57509), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 0.53184 (best 0.53184), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached 0.51201 (best 0.51201), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 0.40579 (best 0.40579), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 0.40139 (best 0.40139), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 0.38327 (best 0.38327), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached 0.30126 (best 0.30126), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 0.26148 (best 0.26148), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached 0.25398 (best 0.25398), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 0.24613 (best 0.24613), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' reached 0.23234 (best 0.23234), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 0.09602 (best 0.09602), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached 0.08620 (best 0.08620), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached 0.06675 (best 0.06675), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' reached 0.02981 (best 0.02981), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached -0.01613 (best -0.01613), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached -0.03485 (best -0.03485), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached -0.04789 (best -0.04789), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached -0.07288 (best -0.07288), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' reached -0.08680 (best -0.08680), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached -0.09973 (best -0.09973), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11056/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 7950.57it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 13:03:36.443507 Saving...\n",
      "2024-08-15 13:03:40.068421 70 / 83 298192\n",
      "2024-08-15 13:03:40.234562 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 8790.62it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d05f912bce4798be3d56bebf2e4e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 1.69302 (best 1.69302), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11058/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 1.05874 (best 1.05874), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11058/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 0.92157 (best 0.92157), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11058/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 0.82946 (best 0.82946), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11058/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 0.65787 (best 0.65787), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11058/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 0.55809 (best 0.55809), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11058/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 0.42653 (best 0.42653), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11058/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' was not in top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 0.32488 (best 0.32488), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11058/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 0.19814 (best 0.19814), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11058/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' was not in top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 0.08652 (best 0.08652), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11058/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 0.06150 (best 0.06150), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11058/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached -0.04622 (best -0.04622), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11058/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached -0.10499 (best -0.10499), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11058/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached -0.10817 (best -0.10817), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11058/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached -0.12459 (best -0.12459), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11058/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached -0.27934 (best -0.27934), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11058/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached -0.31728 (best -0.31728), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11058/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached -0.36337 (best -0.36337), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11058/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached -0.39787 (best -0.39787), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11058/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached -0.49418 (best -0.49418), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11058/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached -0.61153 (best -0.61153), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11058/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached -0.66140 (best -0.66140), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11058/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached -0.75066 (best -0.75066), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11058/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached -0.78343 (best -0.78343), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11058/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached -0.82246 (best -0.82246), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11058/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached -0.84242 (best -0.84242), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11058/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached -0.86222 (best -0.86222), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11058/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached -0.95395 (best -0.95395), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11058/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached -0.97843 (best -0.97843), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11058/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached -0.98644 (best -0.98644), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11058/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached -1.02796 (best -1.02796), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11058/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' reached -1.06095 (best -1.06095), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11058/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 7672.69it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 13:05:07.792909 71 / 83 299856\n",
      "2024-08-15 13:05:07.968592 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 3615.05it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99f339da45484ceba3caa0f27d3a69a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 2.38292 (best 2.38292), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11060/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 1.56640 (best 1.56640), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11060/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 1.44574 (best 1.44574), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11060/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 1.30152 (best 1.30152), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11060/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 1.09287 (best 1.09287), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11060/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 1.05083 (best 1.05083), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11060/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 0.99212 (best 0.99212), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11060/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 0.77438 (best 0.77438), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11060/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 0.69006 (best 0.69006), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11060/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 0.49932 (best 0.49932), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11060/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' was not in top 1\n",
      "Epoch 11, global step 600: 'train_loss' was not in top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 0.39216 (best 0.39216), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11060/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 0.31606 (best 0.31606), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11060/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' was not in top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 0.25876 (best 0.25876), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11060/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 0.23285 (best 0.23285), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11060/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 0.17994 (best 0.17994), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11060/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 0.12550 (best 0.12550), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11060/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 0.02819 (best 0.02819), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11060/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached -0.05713 (best -0.05713), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11060/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached -0.09558 (best -0.09558), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11060/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached -0.10612 (best -0.10612), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11060/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' reached -0.20068 (best -0.20068), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11060/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached -0.23796 (best -0.23796), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11060/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached -0.24872 (best -0.24872), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11060/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached -0.28879 (best -0.28879), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11060/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached -0.34136 (best -0.34136), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11060/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached -0.35939 (best -0.35939), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11060/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached -0.41170 (best -0.41170), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11060/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached -0.44370 (best -0.44370), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11060/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 7601.38it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 13:06:38.905252 Saving...\n",
      "2024-08-15 13:06:42.031005 72 / 83 301315\n",
      "2024-08-15 13:06:42.386305 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 8353.14it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57cd3234eeee4e36b3f26a4534d3fbbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 4.35850 (best 4.35850), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11062/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 3.62943 (best 3.62943), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11062/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 3.53103 (best 3.53103), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11062/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 3.43159 (best 3.43159), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11062/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 3.30182 (best 3.30182), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11062/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 3.29101 (best 3.29101), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11062/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 3.16487 (best 3.16487), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11062/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 3.11563 (best 3.11563), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11062/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 3.02631 (best 3.02631), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11062/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 3.01100 (best 3.01100), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11062/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 2.89841 (best 2.89841), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11062/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 2.80361 (best 2.80361), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11062/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 2.79706 (best 2.79706), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11062/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 2.70233 (best 2.70233), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11062/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 2.64687 (best 2.64687), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11062/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 2.58172 (best 2.58172), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11062/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 2.47351 (best 2.47351), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11062/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 2.39562 (best 2.39562), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11062/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 2.36371 (best 2.36371), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11062/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 2.32746 (best 2.32746), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11062/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached 2.28790 (best 2.28790), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11062/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 2.15757 (best 2.15757), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11062/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 2.10821 (best 2.10821), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11062/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached 2.03158 (best 2.03158), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11062/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 1.93091 (best 1.93091), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11062/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 1.90513 (best 1.90513), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11062/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached 1.86423 (best 1.86423), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11062/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached 1.81830 (best 1.81830), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11062/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' reached 1.80794 (best 1.80794), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11062/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached 1.76297 (best 1.76297), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11062/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached 1.73341 (best 1.73341), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11062/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached 1.70652 (best 1.70652), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11062/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 1.67581 (best 1.67581), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11062/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 6139.09it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 13:08:11.828327 73 / 83 307568\n",
      "2024-08-15 13:08:12.035281 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 6597.08it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a0d86451964d219180f73f7ff1ab51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 2.52490 (best 2.52490), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11064/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 1.89560 (best 1.89560), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11064/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 1.63938 (best 1.63938), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11064/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' was not in top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 1.38120 (best 1.38120), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11064/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 1.28818 (best 1.28818), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11064/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 1.17619 (best 1.17619), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11064/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 1.10916 (best 1.10916), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11064/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' was not in top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 1.01349 (best 1.01349), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11064/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' was not in top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 0.91952 (best 0.91952), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11064/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 0.84354 (best 0.84354), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11064/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 0.82216 (best 0.82216), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11064/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 0.77232 (best 0.77232), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11064/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 0.70929 (best 0.70929), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11064/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' was not in top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 0.69884 (best 0.69884), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11064/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 0.61088 (best 0.61088), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11064/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 0.46194 (best 0.46194), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11064/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 0.44831 (best 0.44831), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11064/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 0.38088 (best 0.38088), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11064/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached 0.28771 (best 0.28771), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11064/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached 0.27741 (best 0.27741), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11064/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 0.12934 (best 0.12934), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11064/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 0.06418 (best 0.06418), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11064/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached 0.00180 (best 0.00180), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11064/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached -0.04436 (best -0.04436), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11064/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached -0.14418 (best -0.14418), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11064/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' reached -0.21731 (best -0.21731), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11064/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 4105.59it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 13:09:43.138070 Saving...\n",
      "2024-08-15 13:09:46.696932 74 / 83 307597\n",
      "2024-08-15 13:09:46.871626 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 7340.30it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70cdc2e8b727487dba70ac11e376e63e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 4.07877 (best 4.07877), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 3.42969 (best 3.42969), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 3.26733 (best 3.26733), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 3.14150 (best 3.14150), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 2.97093 (best 2.97093), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 2.90101 (best 2.90101), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 2.76735 (best 2.76735), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 2.66942 (best 2.66942), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 2.59354 (best 2.59354), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 2.54128 (best 2.54128), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' was not in top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 2.40889 (best 2.40889), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 2.24406 (best 2.24406), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 2.20400 (best 2.20400), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 2.11151 (best 2.11151), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 2.06395 (best 2.06395), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 2.01849 (best 2.01849), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 2.00718 (best 2.00718), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 1.96989 (best 1.96989), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 1.87086 (best 1.87086), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 1.86588 (best 1.86588), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 1.82575 (best 1.82575), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 1.72344 (best 1.72344), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 1.66638 (best 1.66638), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached 1.57792 (best 1.57792), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached 1.52870 (best 1.52870), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 1.44800 (best 1.44800), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached 1.44383 (best 1.44383), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached 1.40937 (best 1.40937), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached 1.35890 (best 1.35890), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached 1.34359 (best 1.34359), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached 1.29683 (best 1.29683), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached 1.27263 (best 1.27263), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached 1.24857 (best 1.24857), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached 1.24258 (best 1.24258), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' reached 1.20649 (best 1.20649), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached 1.19571 (best 1.19571), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11066/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 7710.12it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 13:11:18.064743 75 / 83 312160\n",
      "2024-08-15 13:11:18.230528 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 3729.29it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec0ce0dffb2f4fd9b2d3cb595823024b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 5.62317 (best 5.62317), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11068/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 4.63749 (best 4.63749), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11068/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 4.35710 (best 4.35710), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11068/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 4.19125 (best 4.19125), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11068/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' was not in top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 3.97664 (best 3.97664), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11068/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' was not in top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 3.88435 (best 3.88435), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11068/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 3.76239 (best 3.76239), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11068/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' was not in top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 3.64999 (best 3.64999), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11068/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 3.62869 (best 3.62869), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11068/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' was not in top 1\n",
      "Epoch 13, global step 700: 'train_loss' was not in top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 3.46676 (best 3.46676), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11068/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 3.44238 (best 3.44238), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11068/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 3.39153 (best 3.39153), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11068/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 3.34384 (best 3.34384), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11068/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 3.23894 (best 3.23894), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11068/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached 3.15735 (best 3.15735), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11068/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 3.15132 (best 3.15132), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11068/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 3.14514 (best 3.14514), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11068/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 3.10281 (best 3.10281), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11068/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 3.05585 (best 3.05585), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11068/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached 3.01841 (best 3.01841), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11068/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached 2.99251 (best 2.99251), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11068/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 2.98816 (best 2.98816), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11068/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 2.93248 (best 2.93248), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11068/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached 2.92476 (best 2.92476), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11068/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached 2.90001 (best 2.90001), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11068/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached 2.86408 (best 2.86408), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11068/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' reached 2.85577 (best 2.85577), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11068/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached 2.81257 (best 2.81257), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11068/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 2.79611 (best 2.79611), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11068/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' reached 2.76276 (best 2.76276), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11068/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached 2.74565 (best 2.74565), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11068/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached 2.71655 (best 2.71655), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11068/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 4244.19it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 13:12:46.578398 Saving...\n",
      "2024-08-15 13:12:49.819740 76 / 83 313846\n",
      "2024-08-15 13:12:50.354388 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 8399.40it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0194e1403c7841f2860a5baaa546335a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 4.49882 (best 4.49882), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11070/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 3.91617 (best 3.91617), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11070/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 3.78093 (best 3.78093), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11070/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 3.58072 (best 3.58072), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11070/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 3.43172 (best 3.43172), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11070/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 3.30026 (best 3.30026), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11070/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 3.17861 (best 3.17861), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11070/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 3.09902 (best 3.09902), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11070/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 3.07555 (best 3.07555), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11070/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 2.87726 (best 2.87726), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11070/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 2.78235 (best 2.78235), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11070/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 2.76325 (best 2.76325), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11070/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 2.76300 (best 2.76300), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11070/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 2.59637 (best 2.59637), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11070/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 2.50419 (best 2.50419), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11070/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' was not in top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 2.45824 (best 2.45824), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11070/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 2.40055 (best 2.40055), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11070/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 2.27296 (best 2.27296), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11070/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 2.22146 (best 2.22146), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11070/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 2.18698 (best 2.18698), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11070/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached 2.15114 (best 2.15114), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11070/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached 1.99122 (best 1.99122), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11070/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached 1.96139 (best 1.96139), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11070/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 1.94900 (best 1.94900), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11070/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' reached 1.94301 (best 1.94301), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11070/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 1.81275 (best 1.81275), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11070/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached 1.76192 (best 1.76192), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11070/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached 1.69469 (best 1.69469), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11070/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached 1.68016 (best 1.68016), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11070/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached 1.65620 (best 1.65620), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11070/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached 1.63011 (best 1.63011), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11070/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached 1.52285 (best 1.52285), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11070/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 2992.11it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 13:14:24.742933 77 / 83 337536\n",
      "2024-08-15 13:14:24.915546 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 3175.16it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6c53595cba244a6b68ba70b6da66ab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 2.29222 (best 2.29222), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11072/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 1.74486 (best 1.74486), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11072/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 1.59491 (best 1.59491), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11072/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 1.47525 (best 1.47525), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11072/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 1.32704 (best 1.32704), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11072/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 1.20158 (best 1.20158), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11072/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 1.03975 (best 1.03975), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11072/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 0.96805 (best 0.96805), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11072/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 0.90928 (best 0.90928), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11072/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 0.82689 (best 0.82689), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11072/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 0.71915 (best 0.71915), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11072/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' was not in top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 0.53566 (best 0.53566), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11072/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 0.52125 (best 0.52125), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11072/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 0.43117 (best 0.43117), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11072/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 0.38579 (best 0.38579), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11072/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 0.33548 (best 0.33548), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11072/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 0.24943 (best 0.24943), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11072/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 0.14005 (best 0.14005), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11072/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached -0.03364 (best -0.03364), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11072/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached -0.06132 (best -0.06132), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11072/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached -0.08643 (best -0.08643), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11072/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached -0.14087 (best -0.14087), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11072/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached -0.18767 (best -0.18767), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11072/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' reached -0.20831 (best -0.20831), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11072/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached -0.29273 (best -0.29273), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11072/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached -0.29988 (best -0.29988), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11072/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' reached -0.38592 (best -0.38592), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11072/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached -0.44312 (best -0.44312), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11072/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached -0.48034 (best -0.48034), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11072/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached -0.50329 (best -0.50329), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11072/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached -0.53862 (best -0.53862), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11072/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 3977.71it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 13:15:54.311695 Saving...\n",
      "2024-08-15 13:15:58.026784 78 / 83 337933\n",
      "2024-08-15 13:15:58.350233 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 6890.93it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab0e58be2fe4e2faf214d1c54de1ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 2.66228 (best 2.66228), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11074/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 1.86827 (best 1.86827), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11074/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 1.72349 (best 1.72349), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11074/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 1.66172 (best 1.66172), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11074/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 1.57188 (best 1.57188), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11074/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 1.53345 (best 1.53345), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11074/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 1.48436 (best 1.48436), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11074/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 1.44607 (best 1.44607), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11074/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 1.37814 (best 1.37814), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11074/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 1.34168 (best 1.34168), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11074/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 1.31282 (best 1.31282), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11074/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 1.24849 (best 1.24849), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11074/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' was not in top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 1.19443 (best 1.19443), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11074/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 1.18985 (best 1.18985), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11074/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' was not in top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 0.99422 (best 0.99422), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11074/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 0.76874 (best 0.76874), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11074/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 0.71816 (best 0.71816), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11074/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 0.59174 (best 0.59174), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11074/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached 0.55971 (best 0.55971), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11074/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached 0.43305 (best 0.43305), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11074/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached 0.42088 (best 0.42088), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11074/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' reached 0.25645 (best 0.25645), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11074/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached 0.19212 (best 0.19212), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11074/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached 0.18398 (best 0.18398), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11074/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached 0.14331 (best 0.14331), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11074/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' reached 0.10216 (best 0.10216), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11074/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached 0.08001 (best 0.08001), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11074/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached 0.01274 (best 0.01274), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11074/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached -0.02760 (best -0.02760), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11074/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached -0.05285 (best -0.05285), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11074/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached -0.10752 (best -0.10752), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11074/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 6200.03it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 13:17:31.675809 79 / 83 338160\n",
      "2024-08-15 13:17:32.239787 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 8220.88it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c266948abd3542a29409d843f4ec87c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 1.56194 (best 1.56194), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11076/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 1.12420 (best 1.12420), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11076/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 0.87304 (best 0.87304), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11076/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 0.68048 (best 0.68048), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11076/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 0.46601 (best 0.46601), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11076/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 0.35755 (best 0.35755), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11076/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 0.19374 (best 0.19374), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11076/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 0.10122 (best 0.10122), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11076/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 0.07758 (best 0.07758), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11076/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached -0.03346 (best -0.03346), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11076/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' was not in top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached -0.20456 (best -0.20456), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11076/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' was not in top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached -0.24770 (best -0.24770), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11076/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached -0.32897 (best -0.32897), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11076/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' was not in top 1\n",
      "Epoch 16, global step 850: 'train_loss' was not in top 1\n",
      "Epoch 17, global step 900: 'train_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached -0.36458 (best -0.36458), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11076/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached -0.58692 (best -0.58692), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11076/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached -0.68780 (best -0.68780), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11076/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached -0.69992 (best -0.69992), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11076/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached -0.80364 (best -0.80364), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11076/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached -0.81548 (best -0.81548), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11076/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached -0.86003 (best -0.86003), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11076/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' reached -0.90642 (best -0.90642), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11076/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' reached -0.91380 (best -0.91380), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11076/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached -0.95582 (best -0.95582), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11076/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached -0.97965 (best -0.97965), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11076/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached -1.04166 (best -1.04166), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11076/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached -1.08826 (best -1.08826), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11076/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' reached -1.09693 (best -1.09693), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11076/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached -1.10829 (best -1.10829), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11076/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached -1.14162 (best -1.14162), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11076/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached -1.23676 (best -1.23676), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11076/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' reached -1.25505 (best -1.25505), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11076/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 3548.35it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 13:19:02.247759 Saving...\n",
      "2024-08-15 13:19:06.549825 80 / 83 343232\n",
      "2024-08-15 13:19:06.814576 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 8614.41it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bdb665b862b4d3bb2315d51ab08e1a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 3.68567 (best 3.68567), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11078/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 2.88281 (best 2.88281), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11078/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 2.68169 (best 2.68169), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11078/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 2.54478 (best 2.54478), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11078/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 2.50792 (best 2.50792), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11078/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 2.36413 (best 2.36413), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11078/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' was not in top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 2.19770 (best 2.19770), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11078/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' was not in top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 2.05487 (best 2.05487), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11078/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 2.03105 (best 2.03105), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11078/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 1.92817 (best 1.92817), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11078/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 1.90918 (best 1.90918), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11078/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 1.86077 (best 1.86077), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11078/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 1.76006 (best 1.76006), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11078/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 1.72490 (best 1.72490), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11078/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' was not in top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 1.59879 (best 1.59879), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11078/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 1.59275 (best 1.59275), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11078/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 1.55435 (best 1.55435), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11078/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 1.50643 (best 1.50643), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11078/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' reached 1.44474 (best 1.44474), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11078/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 1.40482 (best 1.40482), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11078/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 1.38641 (best 1.38641), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11078/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached 1.28974 (best 1.28974), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11078/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached 1.26857 (best 1.26857), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11078/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 1.22696 (best 1.22696), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11078/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' reached 1.21178 (best 1.21178), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11078/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 1.16419 (best 1.16419), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11078/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached 1.11855 (best 1.11855), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11078/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' reached 1.10649 (best 1.10649), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11078/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached 1.03458 (best 1.03458), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11078/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached 1.00303 (best 1.00303), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11078/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached 0.96908 (best 0.96908), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11078/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached 0.91883 (best 0.91883), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11078/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 2390.67it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 13:20:34.028196 81 / 83 345283\n",
      "2024-08-15 13:20:34.207736 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 6485.94it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2433f4531fb4123bdbe51e45198c2c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 2.93140 (best 2.93140), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11080/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 2.22748 (best 2.22748), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11080/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 2.18219 (best 2.18219), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11080/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 2.13416 (best 2.13416), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11080/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 2.00265 (best 2.00265), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11080/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 2.00144 (best 2.00144), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11080/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 1.92525 (best 1.92525), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11080/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 1.79056 (best 1.79056), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11080/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' was not in top 1\n",
      "Epoch 9, global step 500: 'train_loss' was not in top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 1.79038 (best 1.79038), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11080/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 1.60189 (best 1.60189), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11080/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' was not in top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 1.52624 (best 1.52624), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11080/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' was not in top 1\n",
      "Epoch 15, global step 800: 'train_loss' was not in top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 1.45453 (best 1.45453), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11080/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 1.37051 (best 1.37051), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11080/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 1.30303 (best 1.30303), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11080/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' reached 1.23966 (best 1.23966), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11080/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
      "Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 1.20704 (best 1.20704), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11080/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 1.11383 (best 1.11383), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11080/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached 1.10444 (best 1.10444), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11080/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 1.10135 (best 1.10135), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11080/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached 1.02715 (best 1.02715), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11080/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached 0.94071 (best 0.94071), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11080/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'train_loss' reached 0.86321 (best 0.86321), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11080/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached 0.80495 (best 0.80495), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11080/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached 0.74495 (best 0.74495), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11080/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached 0.68469 (best 0.68469), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11080/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 0.60741 (best 0.60741), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11080/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 1358.22it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 13:22:03.374074 Saving...\n",
      "2024-08-15 13:22:07.405247 82 / 83 348278\n",
      "2024-08-15 13:22:07.747006 #items 357.0 split 178.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 179it [00:00, 4740.07it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62038d56ce614061806fbcb5619ea255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                 | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 3.83763 (best 3.83763), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11082/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 2.84873 (best 2.84873), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11082/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 2.66314 (best 2.66314), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11082/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 2.66217 (best 2.66217), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11082/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 2.45759 (best 2.45759), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11082/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 2.43634 (best 2.43634), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11082/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 2.26360 (best 2.26360), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11082/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 2.04191 (best 2.04191), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11082/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 2.00772 (best 2.00772), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11082/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' was not in top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 1.93344 (best 1.93344), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11082/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 1.83309 (best 1.83309), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11082/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 1.74235 (best 1.74235), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11082/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' was not in top 1\n",
      "Epoch 14, global step 750: 'train_loss' was not in top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 1.59766 (best 1.59766), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11082/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' was not in top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 1.52889 (best 1.52889), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11082/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 1.50448 (best 1.50448), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11082/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 1.38697 (best 1.38697), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11082/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached 1.32468 (best 1.32468), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11082/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' reached 1.25728 (best 1.25728), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11082/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 1.19805 (best 1.19805), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11082/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 1.17655 (best 1.17655), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11082/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached 1.11499 (best 1.11499), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11082/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached 1.08653 (best 1.08653), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11082/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' reached 1.04888 (best 1.04888), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11082/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
      "Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached 1.00063 (best 1.00063), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11082/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' reached 0.95142 (best 0.95142), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11082/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' reached 0.92306 (best 0.92306), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11082/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 0.89724 (best 0.89724), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11082/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached 0.86785 (best 0.86785), saving model to '/home/user/energygpt/lagllama/lag-llama/lightning_logs/version_11082/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Running evaluation: 179it [00:00, 3550.24it/s]\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/lagllama/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "files_list = glob.glob('/home/user/BuildingsBench/BuildingsBenchData/BuildingsBench/Buildings-900K-test-csv/*.csv')   #Enter Data set location in your comptuer in CSV format\n",
    "print(files_list)\n",
    "\n",
    "dataset = 'Buildings-900K-test-50epoch'  # dataset Name to be processed\n",
    "os.makedirs(f'../forecasts_finetuned/{dataset}/', exist_ok = True)\n",
    "os.makedirs(f'../results_finetuned/{dataset}/', exist_ok = True)\n",
    "\n",
    "for filename in files_list:\n",
    "    print(datetime.now(), filename)\n",
    "    results = process_file(filename)\n",
    " \n",
    "    print('')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40851766-4bab-49f9-a849-122f59fd0a15",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert(False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
